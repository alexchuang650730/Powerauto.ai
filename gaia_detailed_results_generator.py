#!/usr/bin/env python3
"""
GAIAæ¸¬è©¦è©³ç´°çµæœè¡¨æ ¼ç”Ÿæˆå™¨

ç”ŸæˆåŒ…å«é¡Œç›®ã€é æœŸç­”æ¡ˆã€çœŸå¯¦ç­”æ¡ˆã€è§£æ±ºå·¥å…·ã€æ‰€èŠ±æ™‚é–“çš„è©³ç´°è¡¨æ ¼
"""

import json
import pandas as pd
from datetime import datetime
from typing import Dict, Any, List
import os

class GAIADetailedResultsGenerator:
    """GAIAè©³ç´°çµæœè¡¨æ ¼ç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.results_data = []
    
    def process_test_results(self, results_file: str) -> pd.DataFrame:
        """è™•ç†æ¸¬è©¦çµæœä¸¦ç”Ÿæˆè©³ç´°è¡¨æ ¼"""
        
        # è¼‰å…¥æ¸¬è©¦çµæœ
        with open(results_file, 'r', encoding='utf-8') as f:
            test_results = json.load(f)
        
        detailed_results = test_results.get("detailed_results", [])
        
        # è™•ç†æ¯å€‹çµæœ
        table_data = []
        
        for i, result in enumerate(detailed_results, 1):
            row = {
                "åºè™Ÿ": i,
                "é¡Œç›®ID": result.get("question_id", f"question_{i}"),
                "é¡Œç›®": result.get("question", "N/A"),
                "é¡åˆ¥": result.get("category", "unknown"),
                "é›£åº¦": result.get("difficulty", "unknown"),
                "é æœŸç­”æ¡ˆ": result.get("expected_answer", "N/A"),
                "çœŸå¯¦ç­”æ¡ˆ": result.get("actual_answer", "N/A"),
                "æ˜¯å¦æ­£ç¢º": "âœ…" if result.get("correct", False) else "âŒ",
                "ä½¿ç”¨é©é…å™¨": result.get("adapter_used", "unknown"),
                "é©é…å™¨é¡å‹": self._get_adapter_type(result.get("adapter_used", "")),
                "åŸ·è¡Œæ™‚é–“(ç§’)": round(result.get("execution_time", 0), 3),
                "æˆåŠŸç‹€æ…‹": "æˆåŠŸ" if result.get("success", False) else "å¤±æ•—",
                "éŒ¯èª¤ä¿¡æ¯": result.get("error", "") if not result.get("success", False) else "",
                "ç½®ä¿¡åº¦": self._extract_confidence(result),
                "éŸ¿æ‡‰é•·åº¦": len(str(result.get("actual_answer", ""))) if result.get("actual_answer") else 0,
                "è™•ç†å±¤ç´š": self._determine_processing_layer(result.get("adapter_used", "")),
                "å·¥å…·åˆ†é¡": self._classify_tool(result.get("adapter_used", ""))
            }
            
            table_data.append(row)
        
        # å‰µå»ºDataFrame
        df = pd.DataFrame(table_data)
        
        return df
    
    def _get_adapter_type(self, adapter_name: str) -> str:
        """ç²å–é©é…å™¨é¡å‹"""
        adapter_types = {
            "claude": "AIæ¨¡å‹",
            "gemini": "AIæ¨¡å‹", 
            "smart_tool_engine": "å·¥å…·å¼•æ“",
            "webagent": "Webä»£ç†",
            "unified_memory": "è¨˜æ†¶ç³»çµ±",
            "context_monitor": "ç›£æ§ç³»çµ±",
            "sequential_thinking": "æ¨ç†å¼•æ“",
            "kilocode": "ä»£ç¢¼å¼•æ“",
            "cloud_edge_data": "æ•¸æ“šè™•ç†"
        }
        
        for key, value in adapter_types.items():
            if key in adapter_name.lower():
                return value
        
        return "é€šç”¨é©é…å™¨"
    
    def _extract_confidence(self, result: Dict[str, Any]) -> float:
        """æå–ç½®ä¿¡åº¦"""
        # å˜—è©¦å¾åŸå§‹éŸ¿æ‡‰ä¸­æå–ç½®ä¿¡åº¦
        raw_response = result.get("raw_response", {})
        if isinstance(raw_response, dict):
            confidence = raw_response.get("confidence", 0.0)
            if isinstance(confidence, (int, float)):
                return round(confidence, 3)
        
        # æ ¹æ“šåŸ·è¡Œæ™‚é–“å’ŒæˆåŠŸç‹€æ…‹ä¼°ç®—ç½®ä¿¡åº¦
        if result.get("correct", False):
            execution_time = result.get("execution_time", 0)
            if execution_time < 1.0:
                return 0.95
            elif execution_time < 3.0:
                return 0.90
            else:
                return 0.85
        else:
            return 0.30
    
    def _determine_processing_layer(self, adapter_name: str) -> str:
        """ç¢ºå®šè™•ç†å±¤ç´š"""
        layer_mapping = {
            "claude": "LLMå±¤",
            "gemini": "LLMå±¤",
            "smart_tool_engine": "å·¥å…·å±¤",
            "webagent": "æ‡‰ç”¨å±¤",
            "unified_memory": "æ•¸æ“šå±¤",
            "context_monitor": "ç›£æ§å±¤",
            "sequential_thinking": "æ¨ç†å±¤",
            "kilocode": "åŸ·è¡Œå±¤",
            "cloud_edge_data": "åŸºç¤è¨­æ–½å±¤"
        }
        
        for key, value in layer_mapping.items():
            if key in adapter_name.lower():
                return value
        
        return "æœªçŸ¥å±¤"
    
    def _classify_tool(self, adapter_name: str) -> str:
        """å·¥å…·åˆ†é¡"""
        tool_classification = {
            "claude": "èªè¨€æ¨¡å‹",
            "gemini": "èªè¨€æ¨¡å‹",
            "smart_tool_engine": "æ™ºèƒ½å·¥å…·",
            "webagent": "ç¶²çµ¡å·¥å…·",
            "unified_memory": "å­˜å„²å·¥å…·",
            "context_monitor": "ç›£æ§å·¥å…·",
            "sequential_thinking": "æ¨ç†å·¥å…·",
            "kilocode": "ç·¨ç¨‹å·¥å…·",
            "cloud_edge_data": "æ•¸æ“šå·¥å…·"
        }
        
        for key, value in tool_classification.items():
            if key in adapter_name.lower():
                return value
        
        return "é€šç”¨å·¥å…·"
    
    def generate_summary_statistics(self, df: pd.DataFrame) -> Dict[str, Any]:
        """ç”Ÿæˆæ‘˜è¦çµ±è¨ˆ"""
        total_questions = len(df)
        correct_answers = len(df[df["æ˜¯å¦æ­£ç¢º"] == "âœ…"])
        accuracy = correct_answers / total_questions if total_questions > 0 else 0
        
        # æŒ‰é¡åˆ¥çµ±è¨ˆ
        category_stats = df.groupby("é¡åˆ¥").agg({
            "æ˜¯å¦æ­£ç¢º": lambda x: (x == "âœ…").sum(),
            "åºè™Ÿ": "count",
            "åŸ·è¡Œæ™‚é–“(ç§’)": "mean"
        }).rename(columns={"æ˜¯å¦æ­£ç¢º": "æ­£ç¢ºæ•¸", "åºè™Ÿ": "ç¸½æ•¸", "åŸ·è¡Œæ™‚é–“(ç§’)": "å¹³å‡æ™‚é–“"})
        category_stats["æº–ç¢ºç‡"] = category_stats["æ­£ç¢ºæ•¸"] / category_stats["ç¸½æ•¸"]
        
        # æŒ‰é©é…å™¨çµ±è¨ˆ
        adapter_stats = df.groupby("ä½¿ç”¨é©é…å™¨").agg({
            "æ˜¯å¦æ­£ç¢º": lambda x: (x == "âœ…").sum(),
            "åºè™Ÿ": "count",
            "åŸ·è¡Œæ™‚é–“(ç§’)": "mean"
        }).rename(columns={"æ˜¯å¦æ­£ç¢º": "æ­£ç¢ºæ•¸", "åºè™Ÿ": "ç¸½æ•¸", "åŸ·è¡Œæ™‚é–“(ç§’)": "å¹³å‡æ™‚é–“"})
        adapter_stats["æº–ç¢ºç‡"] = adapter_stats["æ­£ç¢ºæ•¸"] / adapter_stats["ç¸½æ•¸"]
        
        # æŒ‰é›£åº¦çµ±è¨ˆ
        difficulty_stats = df.groupby("é›£åº¦").agg({
            "æ˜¯å¦æ­£ç¢º": lambda x: (x == "âœ…").sum(),
            "åºè™Ÿ": "count",
            "åŸ·è¡Œæ™‚é–“(ç§’)": "mean"
        }).rename(columns={"æ˜¯å¦æ­£ç¢º": "æ­£ç¢ºæ•¸", "åºè™Ÿ": "ç¸½æ•¸", "åŸ·è¡Œæ™‚é–“(ç§’)": "å¹³å‡æ™‚é–“"})
        difficulty_stats["æº–ç¢ºç‡"] = difficulty_stats["æ­£ç¢ºæ•¸"] / difficulty_stats["ç¸½æ•¸"]
        
        # æŒ‰è™•ç†å±¤ç´šçµ±è¨ˆ
        layer_stats = df.groupby("è™•ç†å±¤ç´š").agg({
            "æ˜¯å¦æ­£ç¢º": lambda x: (x == "âœ…").sum(),
            "åºè™Ÿ": "count",
            "åŸ·è¡Œæ™‚é–“(ç§’)": "mean"
        }).rename(columns={"æ˜¯å¦æ­£ç¢º": "æ­£ç¢ºæ•¸", "åºè™Ÿ": "ç¸½æ•¸", "åŸ·è¡Œæ™‚é–“(ç§’)": "å¹³å‡æ™‚é–“"})
        layer_stats["æº–ç¢ºç‡"] = layer_stats["æ­£ç¢ºæ•¸"] / layer_stats["ç¸½æ•¸"]
        
        return {
            "ç¸½é«”çµ±è¨ˆ": {
                "ç¸½é¡Œç›®æ•¸": total_questions,
                "æ­£ç¢ºç­”æ¡ˆæ•¸": correct_answers,
                "ç¸½é«”æº–ç¢ºç‡": round(accuracy, 4),
                "å¹³å‡åŸ·è¡Œæ™‚é–“": round(df["åŸ·è¡Œæ™‚é–“(ç§’)"].mean(), 3),
                "ç¸½åŸ·è¡Œæ™‚é–“": round(df["åŸ·è¡Œæ™‚é–“(ç§’)"].sum(), 3)
            },
            "æŒ‰é¡åˆ¥çµ±è¨ˆ": category_stats.round(4).to_dict(),
            "æŒ‰é©é…å™¨çµ±è¨ˆ": adapter_stats.round(4).to_dict(),
            "æŒ‰é›£åº¦çµ±è¨ˆ": difficulty_stats.round(4).to_dict(),
            "æŒ‰è™•ç†å±¤ç´šçµ±è¨ˆ": layer_stats.round(4).to_dict()
        }
    
    def save_detailed_results(self, df: pd.DataFrame, stats: Dict[str, Any], 
                            base_filename: str = None) -> Dict[str, str]:
        """ä¿å­˜è©³ç´°çµæœåˆ°å¤šç¨®æ ¼å¼"""
        
        if base_filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            base_filename = f"/home/ubuntu/Powerauto.ai/gaia_level1_detailed_results_{timestamp}"
        
        saved_files = {}
        
        try:
            # ä¿å­˜ç‚ºExcelæ–‡ä»¶ï¼ˆåŒ…å«å¤šå€‹å·¥ä½œè¡¨ï¼‰
            excel_file = f"{base_filename}.xlsx"
            with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:
                # ä¸»çµæœè¡¨
                df.to_excel(writer, sheet_name='è©³ç´°çµæœ', index=False)
                
                # çµ±è¨ˆè¡¨
                for stat_name, stat_data in stats.items():
                    if isinstance(stat_data, dict) and stat_name != "ç¸½é«”çµ±è¨ˆ":
                        stat_df = pd.DataFrame(stat_data).T
                        sheet_name = stat_name.replace("çµ±è¨ˆ", "")[:31]  # Excelå·¥ä½œè¡¨åç¨±é™åˆ¶
                        stat_df.to_excel(writer, sheet_name=sheet_name)
                
                # ç¸½é«”çµ±è¨ˆ
                overall_stats = pd.DataFrame([stats["ç¸½é«”çµ±è¨ˆ"]])
                overall_stats.to_excel(writer, sheet_name='ç¸½é«”çµ±è¨ˆ', index=False)
            
            saved_files["excel"] = excel_file
            
            # ä¿å­˜ç‚ºCSVæ–‡ä»¶
            csv_file = f"{base_filename}.csv"
            df.to_csv(csv_file, index=False, encoding='utf-8-sig')
            saved_files["csv"] = csv_file
            
            # ä¿å­˜ç‚ºJSONæ–‡ä»¶
            json_file = f"{base_filename}.json"
            result_data = {
                "metadata": {
                    "generated_at": datetime.now().isoformat(),
                    "total_questions": len(df),
                    "data_source": "GAIA Level 1 Complete Test"
                },
                "statistics": stats,
                "detailed_results": df.to_dict('records')
            }
            
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(result_data, f, indent=2, ensure_ascii=False)
            saved_files["json"] = json_file
            
            # ä¿å­˜ç‚ºHTMLè¡¨æ ¼
            html_file = f"{base_filename}.html"
            html_content = self._generate_html_report(df, stats)
            with open(html_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
            saved_files["html"] = html_file
            
            print(f"âœ… è©³ç´°çµæœå·²ä¿å­˜åˆ°:")
            for format_type, file_path in saved_files.items():
                print(f"  {format_type.upper()}: {file_path}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜çµæœæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        
        return saved_files
    
    def _generate_html_report(self, df: pd.DataFrame, stats: Dict[str, Any]) -> str:
        """ç”ŸæˆHTMLå ±å‘Š"""
        
        html_template = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>GAIA Level 1 è©³ç´°æ¸¬è©¦çµæœ</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ background-color: #f0f8ff; padding: 20px; border-radius: 10px; margin-bottom: 20px; }}
        .stats {{ background-color: #f9f9f9; padding: 15px; border-radius: 5px; margin-bottom: 20px; }}
        table {{ border-collapse: collapse; width: 100%; margin-bottom: 20px; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #4CAF50; color: white; }}
        tr:nth-child(even) {{ background-color: #f2f2f2; }}
        .correct {{ color: green; font-weight: bold; }}
        .incorrect {{ color: red; font-weight: bold; }}
        .summary {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; }}
        .summary-card {{ background: white; border: 1px solid #ddd; border-radius: 8px; padding: 15px; }}
        .summary-card h3 {{ margin-top: 0; color: #333; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>ğŸ¯ GAIA Level 1 å®Œæ•´æ¸¬è©¦çµæœå ±å‘Š</h1>
        <p><strong>ç”Ÿæˆæ™‚é–“:</strong> {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
        <p><strong>æ¸¬è©¦é¡Œç›®:</strong> {len(df)} é¡Œ</p>
        <p><strong>ç¸½é«”æº–ç¢ºç‡:</strong> {stats['ç¸½é«”çµ±è¨ˆ']['ç¸½é«”æº–ç¢ºç‡']:.1%}</p>
    </div>
    
    <div class="summary">
        <div class="summary-card">
            <h3>ğŸ“Š ç¸½é«”çµ±è¨ˆ</h3>
            <p><strong>ç¸½é¡Œç›®æ•¸:</strong> {stats['ç¸½é«”çµ±è¨ˆ']['ç¸½é¡Œç›®æ•¸']}</p>
            <p><strong>æ­£ç¢ºç­”æ¡ˆæ•¸:</strong> {stats['ç¸½é«”çµ±è¨ˆ']['æ­£ç¢ºç­”æ¡ˆæ•¸']}</p>
            <p><strong>æº–ç¢ºç‡:</strong> {stats['ç¸½é«”çµ±è¨ˆ']['ç¸½é«”æº–ç¢ºç‡']:.1%}</p>
            <p><strong>å¹³å‡åŸ·è¡Œæ™‚é–“:</strong> {stats['ç¸½é«”çµ±è¨ˆ']['å¹³å‡åŸ·è¡Œæ™‚é–“']:.3f}ç§’</p>
            <p><strong>ç¸½åŸ·è¡Œæ™‚é–“:</strong> {stats['ç¸½é«”çµ±è¨ˆ']['ç¸½åŸ·è¡Œæ™‚é–“']:.3f}ç§’</p>
        </div>
    </div>
    
    <h2>ğŸ“‹ è©³ç´°æ¸¬è©¦çµæœ</h2>
    {df.to_html(classes='table table-striped', escape=False, index=False)}
    
</body>
</html>
        """
        
        return html_template
    
    def print_summary(self, stats: Dict[str, Any]):
        """æ‰“å°æ‘˜è¦çµ±è¨ˆ"""
        print("\\nğŸ“Š GAIA Level 1 å®Œæ•´æ¸¬è©¦æ‘˜è¦")
        print("=" * 50)
        
        overall = stats["ç¸½é«”çµ±è¨ˆ"]
        print(f"ç¸½é¡Œç›®æ•¸: {overall['ç¸½é¡Œç›®æ•¸']}")
        print(f"æ­£ç¢ºç­”æ¡ˆæ•¸: {overall['æ­£ç¢ºç­”æ¡ˆæ•¸']}")
        print(f"ç¸½é«”æº–ç¢ºç‡: {overall['ç¸½é«”æº–ç¢ºç‡']:.1%}")
        print(f"å¹³å‡åŸ·è¡Œæ™‚é–“: {overall['å¹³å‡åŸ·è¡Œæ™‚é–“']:.3f}ç§’")
        print(f"ç¸½åŸ·è¡Œæ™‚é–“: {overall['ç¸½åŸ·è¡Œæ™‚é–“']:.3f}ç§’")
        
        print("\\nğŸ“‹ æŒ‰é¡åˆ¥çµ±è¨ˆ:")
        for category, data in stats["æŒ‰é¡åˆ¥çµ±è¨ˆ"].items():
            if isinstance(data, dict):
                correct = data.get('æ­£ç¢ºæ•¸', 0)
                total = data.get('ç¸½æ•¸', 0) 
                accuracy = data.get('æº–ç¢ºç‡', 0)
                avg_time = data.get('å¹³å‡æ™‚é–“', 0)
                print(f"  {category}: {correct}/{total} ({accuracy:.1%}) - å¹³å‡{avg_time:.2f}ç§’")
        
        print("\\nğŸ¤– æŒ‰é©é…å™¨çµ±è¨ˆ:")
        for adapter, data in stats["æŒ‰é©é…å™¨çµ±è¨ˆ"].items():
            if isinstance(data, dict):
                correct = data.get('æ­£ç¢ºæ•¸', 0)
                total = data.get('ç¸½æ•¸', 0)
                accuracy = data.get('æº–ç¢ºç‡', 0)
                avg_time = data.get('å¹³å‡æ™‚é–“', 0)
                print(f"  {adapter}: {correct}/{total} ({accuracy:.1%}) - å¹³å‡{avg_time:.2f}ç§’")
        
        print("\\nğŸ¯ æŒ‰é›£åº¦çµ±è¨ˆ:")
        for difficulty, data in stats["æŒ‰é›£åº¦çµ±è¨ˆ"].items():
            if isinstance(data, dict):
                correct = data.get('æ­£ç¢ºæ•¸', 0)
                total = data.get('ç¸½æ•¸', 0)
                accuracy = data.get('æº–ç¢ºç‡', 0)
                avg_time = data.get('å¹³å‡æ™‚é–“', 0)
                print(f"  {difficulty}: {correct}/{total} ({accuracy:.1%}) - å¹³å‡{avg_time:.2f}ç§’")

# æ¸¬è©¦è…³æœ¬
if __name__ == "__main__":
    print("ğŸ“Š GAIAè©³ç´°çµæœè¡¨æ ¼ç”Ÿæˆå™¨æ¸¬è©¦")
    
    # å‰µå»ºç”Ÿæˆå™¨
    generator = GAIADetailedResultsGenerator()
    
    # æ¨¡æ“¬æ¸¬è©¦çµæœæ•¸æ“š
    sample_results = {
        "summary": {
            "total_questions": 5,
            "correct_answers": 4,
            "accuracy": 0.8
        },
        "detailed_results": [
            {
                "question_id": "gaia_001",
                "question": "What is the capital of France?",
                "expected_answer": "Paris",
                "actual_answer": "Paris",
                "correct": True,
                "adapter_used": "claude",
                "execution_time": 1.234,
                "success": True,
                "category": "geography",
                "difficulty": "easy"
            },
            {
                "question_id": "gaia_002",
                "question": "What is 15 + 27?",
                "expected_answer": "42",
                "actual_answer": "42",
                "correct": True,
                "adapter_used": "gemini",
                "execution_time": 0.856,
                "success": True,
                "category": "math",
                "difficulty": "easy"
            }
        ]
    }
    
    # ä¿å­˜æ¨£æœ¬æ•¸æ“š
    sample_file = "/home/ubuntu/Powerauto.ai/sample_test_results.json"
    with open(sample_file, 'w', encoding='utf-8') as f:
        json.dump(sample_results, f, indent=2, ensure_ascii=False)
    
    # è™•ç†çµæœ
    df = generator.process_test_results(sample_file)
    stats = generator.generate_summary_statistics(df)
    
    # æ‰“å°æ‘˜è¦
    generator.print_summary(stats)
    
    # ä¿å­˜çµæœ
    saved_files = generator.save_detailed_results(df, stats, "/home/ubuntu/Powerauto.ai/sample_detailed_results")
    
    print("\\nğŸ¯ è©³ç´°çµæœè¡¨æ ¼ç”Ÿæˆå™¨æ¸¬è©¦å®Œæˆ")

