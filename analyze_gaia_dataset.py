#!/usr/bin/env python3
"""
çµ±è¨ˆGAIAæ•¸æ“šé›†çš„å®Œæ•´åˆ†å¸ƒ
"""

from datasets import load_dataset
import json

def analyze_gaia_dataset():
    print("ğŸ” æ­£åœ¨åˆ†æGAIAæ•¸æ“šé›†çš„å®Œæ•´åˆ†å¸ƒ...")
    
    try:
        # åŠ è¼‰å®Œæ•´æ•¸æ“šé›†
        dataset = load_dataset('gaia-benchmark/GAIA', '2023_all', trust_remote_code=True)
        
        print(f"ğŸ“Š GAIAæ•¸æ“šé›†ç¸½è¦½:")
        print(f"   - è¨“ç·´é›†: {len(dataset['train'])} å€‹å•é¡Œ")
        print(f"   - é©—è­‰é›†: {len(dataset['validation'])} å€‹å•é¡Œ") 
        print(f"   - æ¸¬è©¦é›†: {len(dataset['test'])} å€‹å•é¡Œ")
        print(f"   - ç¸½è¨ˆ: {len(dataset['train']) + len(dataset['validation']) + len(dataset['test'])} å€‹å•é¡Œ")
        
        # çµ±è¨ˆå„å€‹åˆ†å‰²çš„Levelåˆ†å¸ƒ
        splits = ['train', 'validation', 'test']
        total_stats = {'Level 1': 0, 'Level 2': 0, 'Level 3': 0}
        
        for split in splits:
            print(f"\nğŸ“ˆ {split.upper()}é›†Levelåˆ†å¸ƒ:")
            level_count = {}
            
            for item in dataset[split]:
                level = item.get('Level', 'Unknown')
                level_key = f'Level {level}'
                level_count[level_key] = level_count.get(level_key, 0) + 1
                total_stats[level_key] = total_stats.get(level_key, 0) + 1
            
            for level in sorted(level_count.keys()):
                count = level_count[level]
                percentage = (count / len(dataset[split])) * 100
                print(f"   - {level}: {count} å€‹å•é¡Œ ({percentage:.1f}%)")
        
        print(f"\nğŸ¯ ç¸½é«”Levelåˆ†å¸ƒ:")
        total_questions = sum(total_stats.values())
        for level in sorted(total_stats.keys()):
            count = total_stats[level]
            percentage = (count / total_questions) * 100
            print(f"   - {level}: {count} å€‹å•é¡Œ ({percentage:.1f}%)")
        
        # æª¢æŸ¥æ–‡ä»¶é™„ä»¶æƒ…æ³
        print(f"\nğŸ“ æ–‡ä»¶é™„ä»¶çµ±è¨ˆ:")
        for split in splits:
            with_files = 0
            without_files = 0
            
            for item in dataset[split]:
                if item.get('file_name'):
                    with_files += 1
                else:
                    without_files += 1
            
            total = len(dataset[split])
            print(f"   - {split.upper()}é›†: {with_files} å€‹æœ‰é™„ä»¶ ({(with_files/total)*100:.1f}%), {without_files} å€‹ç„¡é™„ä»¶ ({(without_files/total)*100:.1f}%)")
        
        # æª¢æŸ¥å•é¡Œé•·åº¦åˆ†å¸ƒ
        print(f"\nğŸ“ å•é¡Œé•·åº¦çµ±è¨ˆ:")
        for split in splits:
            lengths = [len(item['Question']) for item in dataset[split]]
            avg_length = sum(lengths) / len(lengths)
            min_length = min(lengths)
            max_length = max(lengths)
            print(f"   - {split.upper()}é›†: å¹³å‡ {avg_length:.0f} å­—ç¬¦, æœ€çŸ­ {min_length}, æœ€é•· {max_length}")
        
        # ä¿å­˜è©³ç´°çµ±è¨ˆ
        detailed_stats = {
            'dataset_overview': {
                'train_size': len(dataset['train']),
                'validation_size': len(dataset['validation']),
                'test_size': len(dataset['test']),
                'total_size': len(dataset['train']) + len(dataset['validation']) + len(dataset['test'])
            },
            'level_distribution': {},
            'file_attachment_stats': {},
            'question_length_stats': {}
        }
        
        # è©³ç´°Levelåˆ†å¸ƒ
        for split in splits:
            level_count = {}
            for item in dataset[split]:
                level = item.get('Level', 'Unknown')
                level_key = f'Level {level}'
                level_count[level_key] = level_count.get(level_key, 0) + 1
            detailed_stats['level_distribution'][split] = level_count
        
        # æ–‡ä»¶é™„ä»¶çµ±è¨ˆ
        for split in splits:
            with_files = sum(1 for item in dataset[split] if item.get('file_name'))
            without_files = len(dataset[split]) - with_files
            detailed_stats['file_attachment_stats'][split] = {
                'with_files': with_files,
                'without_files': without_files,
                'total': len(dataset[split])
            }
        
        # å•é¡Œé•·åº¦çµ±è¨ˆ
        for split in splits:
            lengths = [len(item['Question']) for item in dataset[split]]
            detailed_stats['question_length_stats'][split] = {
                'average': sum(lengths) / len(lengths),
                'min': min(lengths),
                'max': max(lengths)
            }
        
        # ä¿å­˜çµ±è¨ˆçµæœ
        with open('gaia_dataset_statistics.json', 'w', encoding='utf-8') as f:
            json.dump(detailed_stats, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è©³ç´°çµ±è¨ˆå·²ä¿å­˜åˆ°: gaia_dataset_statistics.json")
        
        return detailed_stats
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±æ•—: {e}")
        return None

if __name__ == "__main__":
    stats = analyze_gaia_dataset()

