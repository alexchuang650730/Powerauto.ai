#!/usr/bin/env python3
"""
RL_SRT + ç•°æ­¥RL + Qwen MCP å¯ç”¨æ€§æ¸¬è©¦å™¨
æª¢æŸ¥é€™äº›çµ„ä»¶åœ¨WSL+Macçµ‚ç«¯ç’°å¢ƒä¸‹çš„å…¼å®¹æ€§
"""

import os
import sys
import json
import asyncio
import logging
import platform
import subprocess
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime

logger = logging.getLogger(__name__)

class MCPCompatibilityTester:
    """MCPå…¼å®¹æ€§æ¸¬è©¦å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¸¬è©¦å™¨"""
        self.platform = platform.system().lower()
        self.is_wsl = self._detect_wsl()
        self.test_results = {}
        
        logger.info(f"MCPå…¼å®¹æ€§æ¸¬è©¦å™¨åˆå§‹åŒ– - å¹³å°: {self.platform}, WSL: {self.is_wsl}")
    
    def _detect_wsl(self) -> bool:
        """æª¢æ¸¬WSLç’°å¢ƒ"""
        try:
            if self.platform == "linux":
                with open('/proc/version', 'r') as f:
                    return 'microsoft' in f.read().lower()
        except:
            pass
        return False
    
    async def test_qwen_mcp(self) -> Dict[str, Any]:
        """æ¸¬è©¦Qwen MCPå¯ç”¨æ€§"""
        test_name = "Qwen MCP"
        logger.info(f"é–‹å§‹æ¸¬è©¦ {test_name}...")
        
        result = {
            "name": test_name,
            "status": "unknown",
            "details": {},
            "recommendations": []
        }
        
        try:
            # æª¢æŸ¥Qwen MCPæ–‡ä»¶
            qwen_file = "/home/ubuntu/Powerauto.ai/mcptool/adapters/qwen3_8b_local_mcp.py"
            if os.path.exists(qwen_file):
                result["details"]["file_exists"] = True
                
                # å˜—è©¦å°å…¥
                try:
                    sys.path.append("/home/ubuntu/Powerauto.ai")
                    from mcptool.adapters.qwen3_8b_local_mcp import Qwen3LocalModelMCP
                    result["details"]["import_success"] = True
                    
                    # å‰µå»ºå¯¦ä¾‹
                    qwen_mcp = Qwen3LocalModelMCP()
                    result["details"]["instance_created"] = True
                    
                    # æª¢æŸ¥Ollamaä¾è³´
                    ollama_available = await self._check_ollama()
                    result["details"]["ollama_available"] = ollama_available
                    
                    if ollama_available:
                        result["status"] = "available"
                        result["details"]["message"] = "Qwen MCPå®Œå…¨å¯ç”¨"
                    else:
                        result["status"] = "needs_setup"
                        result["details"]["message"] = "éœ€è¦å®‰è£Ollama"
                        result["recommendations"].append("é‹è¡Œ: curl -fsSL https://ollama.ai/install.sh | sh")
                        result["recommendations"].append("ç„¶å¾Œ: ollama pull qwen2.5:8b")
                    
                except ImportError as e:
                    result["details"]["import_error"] = str(e)
                    result["status"] = "import_failed"
                    result["recommendations"].append("æª¢æŸ¥Pythonä¾è³´")
                    
            else:
                result["details"]["file_exists"] = False
                result["status"] = "not_found"
                result["recommendations"].append("Qwen MCPæ–‡ä»¶ä¸å­˜åœ¨")
                
        except Exception as e:
            result["status"] = "error"
            result["details"]["error"] = str(e)
        
        return result
    
    async def test_rl_srt_mcp(self) -> Dict[str, Any]:
        """æ¸¬è©¦RL_SRT MCPå¯ç”¨æ€§"""
        test_name = "RL_SRT MCP"
        logger.info(f"é–‹å§‹æ¸¬è©¦ {test_name}...")
        
        result = {
            "name": test_name,
            "status": "unknown",
            "details": {},
            "recommendations": []
        }
        
        try:
            # æª¢æŸ¥RL_SRTæ–‡ä»¶
            rl_files = [
                "/home/ubuntu/Powerauto.ai/mcptool/adapters/rl_srt/rl_srt_mcp.py",
                "/home/ubuntu/Powerauto.ai/mcptool/adapters/rl_srt_dataflow_mcp.py"
            ]
            
            files_exist = [os.path.exists(f) for f in rl_files]
            result["details"]["files_exist"] = dict(zip(rl_files, files_exist))
            
            if any(files_exist):
                # æª¢æŸ¥PyTorchä¾è³´
                pytorch_available = await self._check_pytorch()
                result["details"]["pytorch_available"] = pytorch_available
                
                # å˜—è©¦å°å…¥
                try:
                    sys.path.append("/home/ubuntu/Powerauto.ai")
                    from mcptool.adapters.rl_srt.rl_srt_mcp import RLSRTAdapter
                    result["details"]["import_success"] = True
                    
                    # å‰µå»ºå¯¦ä¾‹
                    rl_adapter = RLSRTAdapter()
                    result["details"]["instance_created"] = True
                    
                    if pytorch_available:
                        result["status"] = "available"
                        result["details"]["message"] = "RL_SRT MCPå®Œå…¨å¯ç”¨"
                    else:
                        result["status"] = "limited"
                        result["details"]["message"] = "RL_SRTå¯ç”¨ä½†åŠŸèƒ½å—é™ï¼ˆç„¡PyTorchï¼‰"
                        result["recommendations"].append("å®‰è£PyTorch: pip install torch")
                    
                except ImportError as e:
                    result["details"]["import_error"] = str(e)
                    result["status"] = "import_failed"
                    result["recommendations"].append("æª¢æŸ¥ä¾è³´å’Œè·¯å¾‘")
                    
            else:
                result["status"] = "not_found"
                result["recommendations"].append("RL_SRT MCPæ–‡ä»¶ä¸å­˜åœ¨")
                
        except Exception as e:
            result["status"] = "error"
            result["details"]["error"] = str(e)
        
        return result
    
    async def test_async_rl(self) -> Dict[str, Any]:
        """æ¸¬è©¦ç•°æ­¥RLåŠŸèƒ½"""
        test_name = "ç•°æ­¥RL"
        logger.info(f"é–‹å§‹æ¸¬è©¦ {test_name}...")
        
        result = {
            "name": test_name,
            "status": "unknown",
            "details": {},
            "recommendations": []
        }
        
        try:
            # æª¢æŸ¥ç•°æ­¥æ”¯æŒ
            asyncio_available = True
            result["details"]["asyncio_available"] = asyncio_available
            
            # æª¢æŸ¥RLç›¸é—œæ–‡ä»¶
            rl_dataflow_file = "/home/ubuntu/Powerauto.ai/mcptool/adapters/rl_srt_dataflow_mcp.py"
            if os.path.exists(rl_dataflow_file):
                result["details"]["dataflow_file_exists"] = True
                
                # æ¸¬è©¦ç•°æ­¥åŠŸèƒ½
                try:
                    async def test_async():
                        await asyncio.sleep(0.1)
                        return True
                    
                    async_test_result = await test_async()
                    result["details"]["async_test_passed"] = async_test_result
                    
                    result["status"] = "available"
                    result["details"]["message"] = "ç•°æ­¥RLåŠŸèƒ½å¯ç”¨"
                    
                except Exception as e:
                    result["details"]["async_error"] = str(e)
                    result["status"] = "limited"
                    result["recommendations"].append("æª¢æŸ¥ç•°æ­¥ç’°å¢ƒé…ç½®")
                    
            else:
                result["status"] = "not_found"
                result["recommendations"].append("ç•°æ­¥RLæ•¸æ“šæµæ–‡ä»¶ä¸å­˜åœ¨")
                
        except Exception as e:
            result["status"] = "error"
            result["details"]["error"] = str(e)
        
        return result
    
    async def test_terminal_compatibility(self) -> Dict[str, Any]:
        """æ¸¬è©¦çµ‚ç«¯å…¼å®¹æ€§"""
        test_name = "çµ‚ç«¯å…¼å®¹æ€§"
        logger.info(f"é–‹å§‹æ¸¬è©¦ {test_name}...")
        
        result = {
            "name": test_name,
            "status": "unknown",
            "details": {},
            "recommendations": []
        }
        
        try:
            # æª¢æŸ¥ç’°å¢ƒè®Šé‡
            env_vars = {
                "TERM": os.getenv("TERM"),
                "SHELL": os.getenv("SHELL"),
                "PATH": len(os.getenv("PATH", "").split(":")),
                "PYTHON_PATH": sys.executable
            }
            result["details"]["environment"] = env_vars
            
            # æª¢æŸ¥Pythonç‰ˆæœ¬
            python_version = sys.version_info
            result["details"]["python_version"] = f"{python_version.major}.{python_version.minor}.{python_version.micro}"
            
            # æª¢æŸ¥å¹³å°ç‰¹å®šåŠŸèƒ½
            platform_info = {
                "system": self.platform,
                "is_wsl": self.is_wsl,
                "architecture": platform.machine(),
                "processor": platform.processor()
            }
            result["details"]["platform"] = platform_info
            
            # WSLç‰¹å®šæª¢æŸ¥
            if self.is_wsl:
                result["details"]["wsl_specific"] = await self._check_wsl_features()
                result["status"] = "wsl_compatible"
                result["details"]["message"] = "WSLç’°å¢ƒå…¼å®¹"
            elif self.platform == "darwin":
                result["status"] = "mac_compatible"
                result["details"]["message"] = "Macç’°å¢ƒå…¼å®¹"
            else:
                result["status"] = "linux_compatible"
                result["details"]["message"] = "Linuxç’°å¢ƒå…¼å®¹"
                
        except Exception as e:
            result["status"] = "error"
            result["details"]["error"] = str(e)
        
        return result
    
    async def _check_ollama(self) -> bool:
        """æª¢æŸ¥Ollamaå¯ç”¨æ€§"""
        try:
            result = subprocess.run(['ollama', '--version'], 
                                  capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except:
            return False
    
    async def _check_pytorch(self) -> bool:
        """æª¢æŸ¥PyTorchå¯ç”¨æ€§"""
        try:
            import torch
            return True
        except ImportError:
            return False
    
    async def _check_wsl_features(self) -> Dict[str, Any]:
        """æª¢æŸ¥WSLç‰¹å®šåŠŸèƒ½"""
        features = {}
        
        try:
            # æª¢æŸ¥WSLç‰ˆæœ¬
            result = subprocess.run(['wsl', '--version'], 
                                  capture_output=True, text=True, timeout=5)
            features["wsl_version_available"] = result.returncode == 0
            if result.returncode == 0:
                features["wsl_version_output"] = result.stdout.strip()
        except:
            features["wsl_version_available"] = False
        
        try:
            # æª¢æŸ¥Windowsäº’æ“ä½œæ€§
            features["windows_interop"] = os.path.exists("/mnt/c")
        except:
            features["windows_interop"] = False
        
        return features
    
    async def run_all_tests(self) -> Dict[str, Any]:
        """é‹è¡Œæ‰€æœ‰æ¸¬è©¦"""
        logger.info("é–‹å§‹é‹è¡Œæ‰€æœ‰MCPå…¼å®¹æ€§æ¸¬è©¦...")
        
        tests = [
            self.test_qwen_mcp(),
            self.test_rl_srt_mcp(),
            self.test_async_rl(),
            self.test_terminal_compatibility()
        ]
        
        results = await asyncio.gather(*tests)
        
        # åŒ¯ç¸½çµæœ
        summary = {
            "test_time": datetime.now().isoformat(),
            "platform": self.platform,
            "is_wsl": self.is_wsl,
            "total_tests": len(results),
            "passed": len([r for r in results if r["status"] in ["available", "wsl_compatible", "mac_compatible", "linux_compatible"]]),
            "failed": len([r for r in results if r["status"] in ["error", "not_found", "import_failed"]]),
            "limited": len([r for r in results if r["status"] in ["limited", "needs_setup"]]),
            "results": results
        }
        
        return summary


async def main():
    """ä¸»æ¸¬è©¦å‡½æ•¸"""
    print("ğŸ§ª MCPå…¼å®¹æ€§æ¸¬è©¦é–‹å§‹\\n")
    
    tester = MCPCompatibilityTester()
    summary = await tester.run_all_tests()
    
    print(f"ğŸ“Š æ¸¬è©¦æ‘˜è¦:")
    print(f"å¹³å°: {summary['platform']} {'(WSL)' if summary['is_wsl'] else ''}")
    print(f"ç¸½æ¸¬è©¦æ•¸: {summary['total_tests']}")
    print(f"âœ… é€šé: {summary['passed']}")
    print(f"âš ï¸ å—é™: {summary['limited']}")
    print(f"âŒ å¤±æ•—: {summary['failed']}")
    print()
    
    for result in summary["results"]:
        status_emoji = {
            "available": "âœ…",
            "wsl_compatible": "âœ…",
            "mac_compatible": "âœ…", 
            "linux_compatible": "âœ…",
            "limited": "âš ï¸",
            "needs_setup": "âš ï¸",
            "error": "âŒ",
            "not_found": "âŒ",
            "import_failed": "âŒ"
        }.get(result["status"], "â“")
        
        print(f"{status_emoji} {result['name']}: {result['status']}")
        if "message" in result["details"]:
            print(f"   {result['details']['message']}")
        
        if result["recommendations"]:
            print("   å»ºè­°:")
            for rec in result["recommendations"]:
                print(f"   - {rec}")
        print()
    
    # ä¿å­˜è©³ç´°çµæœ
    with open("/home/ubuntu/Powerauto.ai/mcp_compatibility_test_results.json", "w", encoding="utf-8") as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)
    
    print("ğŸ“„ è©³ç´°çµæœå·²ä¿å­˜åˆ°: mcp_compatibility_test_results.json")

if __name__ == "__main__":
    asyncio.run(main())

