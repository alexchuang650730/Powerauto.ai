# CLIæ•¸æ“šåˆ†é¡å’Œå­˜å„²ç³»çµ±è¨­è¨ˆ

## ğŸ“‹ åŸºæ–¼å°è©±æ•¸æ“šåˆ†é¡çš„CLIæ•¸æ“šæ¶æ§‹

### ğŸ¯ è¨­è¨ˆåŸå‰‡

åƒè€ƒä¹‹å‰çš„å°è©±æ•¸æ“šåˆ†é¡æ–¹æ¡ˆï¼ŒCLIæ•¸æ“šåˆ†é¡éœ€è¦è€ƒæ…®ï¼š
1. **ä»»å‹™é¡å‹åˆ†é¡** - ä¸åŒé¡å‹çš„CLIä»»å‹™
2. **äº¤äº’æ¨¡å¼åˆ†é¡** - ç”¨æˆ¶èˆ‡CLIçš„äº¤äº’æ–¹å¼
3. **çµæœè³ªé‡åˆ†é¡** - åŸ·è¡Œçµæœçš„è³ªé‡è©•ä¼°
4. **å­¸ç¿’åƒ¹å€¼åˆ†é¡** - å°è¨“ç·´çš„åƒ¹å€¼ç¨‹åº¦

---

## ğŸ—ï¸ CLIæ•¸æ“šåˆ†é¡æ¶æ§‹

### 1. ä¸»è¦åˆ†é¡ç¶­åº¦

#### A. ä»»å‹™é¡å‹åˆ†é¡ (Task Type Classification)
```json
{
  "task_categories": {
    "gaia_testing": {
      "description": "GAIAåŸºæº–æ¸¬è©¦ç›¸é—œä»»å‹™",
      "subcategories": ["level1", "level2", "level3", "validation", "analysis"]
    },
    "mcp_management": {
      "description": "MCPé©é…å™¨ç®¡ç†ä»»å‹™", 
      "subcategories": ["list", "load", "test", "configure", "debug"]
    },
    "data_analysis": {
      "description": "æ•¸æ“šåˆ†æå’Œè™•ç†ä»»å‹™",
      "subcategories": ["file_analysis", "statistical_analysis", "visualization", "reporting"]
    },
    "code_generation": {
      "description": "ä»£ç¢¼ç”Ÿæˆå’ŒåŸ·è¡Œä»»å‹™",
      "subcategories": ["script_generation", "debugging", "optimization", "testing"]
    },
    "system_operation": {
      "description": "ç³»çµ±æ“ä½œå’Œç¶­è­·ä»»å‹™",
      "subcategories": ["status_check", "configuration", "monitoring", "troubleshooting"]
    }
  }
}
```

#### B. äº¤äº’è¤‡é›œåº¦åˆ†é¡ (Interaction Complexity)
```json
{
  "complexity_levels": {
    "simple": {
      "description": "å–®ä¸€å‘½ä»¤ï¼Œç›´æ¥çµæœ",
      "examples": ["--status", "--list", "--help"],
      "training_value": "low"
    },
    "moderate": {
      "description": "å¤šåƒæ•¸å‘½ä»¤ï¼Œéœ€è¦è™•ç†",
      "examples": ["--gaia --level 1 --max-tasks 5"],
      "training_value": "medium"
    },
    "complex": {
      "description": "å¤šæ­¥é©Ÿäº¤äº’ï¼Œè¤‡é›œé‚è¼¯",
      "examples": ["interactive debugging", "multi-tool coordination"],
      "training_value": "high"
    },
    "expert": {
      "description": "é«˜ç´šé…ç½®ï¼Œå°ˆå®¶ç´šæ“ä½œ",
      "examples": ["custom adapter creation", "system optimization"],
      "training_value": "very_high"
    }
  }
}
```

#### C. åŸ·è¡Œçµæœåˆ†é¡ (Execution Result Classification)
```json
{
  "result_categories": {
    "success": {
      "perfect": "å®Œå…¨æˆåŠŸï¼Œçµæœæº–ç¢º",
      "partial": "éƒ¨åˆ†æˆåŠŸï¼Œæœ‰æ”¹é€²ç©ºé–“",
      "acceptable": "å¯æ¥å—çš„çµæœï¼Œä½†ä¸å®Œç¾"
    },
    "failure": {
      "user_error": "ç”¨æˆ¶è¼¸å…¥éŒ¯èª¤",
      "system_error": "ç³»çµ±å…§éƒ¨éŒ¯èª¤", 
      "configuration_error": "é…ç½®å•é¡Œ",
      "resource_error": "è³‡æºä¸è¶³"
    },
    "learning_opportunity": {
      "novel_pattern": "æ–°çš„ä½¿ç”¨æ¨¡å¼",
      "edge_case": "é‚Šç•Œæƒ…æ³",
      "optimization_potential": "å„ªåŒ–æ½›åŠ›",
      "feature_request": "åŠŸèƒ½éœ€æ±‚"
    }
  }
}
```

#### D. å­¸ç¿’åƒ¹å€¼åˆ†é¡ (Learning Value Classification)
```json
{
  "learning_value": {
    "high_value": {
      "criteria": ["novel solutions", "high success rate", "complex problems"],
      "use_cases": ["model training", "best practice extraction", "pattern recognition"]
    },
    "medium_value": {
      "criteria": ["common patterns", "moderate complexity", "typical workflows"],
      "use_cases": ["workflow optimization", "user experience improvement"]
    },
    "low_value": {
      "criteria": ["routine operations", "simple commands", "standard procedures"],
      "use_cases": ["system monitoring", "basic statistics"]
    },
    "negative_value": {
      "criteria": ["errors", "failures", "misuse"],
      "use_cases": ["error prevention", "robustness improvement", "user guidance"]
    }
  }
}
```

---

## ğŸ“Š CLIæ•¸æ“šçµæ§‹å®šç¾©

### æ ¸å¿ƒæ•¸æ“šæ¨¡å‹

```python
from dataclasses import dataclass
from typing import Dict, List, Any, Optional
from datetime import datetime
from enum import Enum

class TaskType(Enum):
    GAIA_TESTING = "gaia_testing"
    MCP_MANAGEMENT = "mcp_management" 
    DATA_ANALYSIS = "data_analysis"
    CODE_GENERATION = "code_generation"
    SYSTEM_OPERATION = "system_operation"

class ComplexityLevel(Enum):
    SIMPLE = "simple"
    MODERATE = "moderate"
    COMPLEX = "complex"
    EXPERT = "expert"

class ResultStatus(Enum):
    SUCCESS_PERFECT = "success_perfect"
    SUCCESS_PARTIAL = "success_partial"
    SUCCESS_ACCEPTABLE = "success_acceptable"
    FAILURE_USER = "failure_user"
    FAILURE_SYSTEM = "failure_system"
    FAILURE_CONFIG = "failure_config"
    FAILURE_RESOURCE = "failure_resource"

class LearningValue(Enum):
    HIGH = "high_value"
    MEDIUM = "medium_value"
    LOW = "low_value"
    NEGATIVE = "negative_value"

@dataclass
class CLIInteractionData:
    """CLIäº¤äº’æ•¸æ“šçµæ§‹"""
    
    # åŸºæœ¬ä¿¡æ¯
    session_id: str
    timestamp: datetime
    user_id: Optional[str] = None  # åŒ¿ååŒ–è™•ç†
    
    # è¼¸å…¥ä¿¡æ¯
    command: str
    arguments: Dict[str, Any]
    context: Dict[str, Any]
    
    # åˆ†é¡ä¿¡æ¯
    task_type: TaskType
    task_subcategory: str
    complexity_level: ComplexityLevel
    
    # åŸ·è¡Œä¿¡æ¯
    execution_time: float
    tools_used: List[str]
    mcp_adapters_involved: List[str]
    
    # çµæœä¿¡æ¯
    result_status: ResultStatus
    output_data: Dict[str, Any]
    error_info: Optional[Dict[str, Any]]
    
    # è³ªé‡è©•ä¼°
    accuracy_score: Optional[float]
    user_satisfaction: Optional[int]  # 1-5è©•åˆ†
    learning_value: LearningValue
    
    # å…ƒæ•¸æ“š
    system_version: str
    environment_info: Dict[str, Any]
    
    def to_training_format(self) -> Dict[str, Any]:
        """è½‰æ›ç‚ºè¨“ç·´æ•¸æ“šæ ¼å¼"""
        return {
            "input": {
                "task_type": self.task_type.value,
                "complexity": self.complexity_level.value,
                "command": self.command,
                "arguments": self.arguments,
                "context": self.context
            },
            "process": {
                "tools_used": self.tools_used,
                "mcp_adapters": self.mcp_adapters_involved,
                "execution_time": self.execution_time
            },
            "output": {
                "status": self.result_status.value,
                "accuracy": self.accuracy_score,
                "satisfaction": self.user_satisfaction,
                "learning_value": self.learning_value.value
            },
            "metadata": {
                "timestamp": self.timestamp.isoformat(),
                "session_id": self.session_id,
                "version": self.system_version
            }
        }
```

---

## ğŸ—‚ï¸ å­˜å„²æ¶æ§‹è¨­è¨ˆ

### 1. åˆ†å±¤å­˜å„²çµæ§‹

```
cli_training_data/
â”œâ”€â”€ raw_data/                    # åŸå§‹æ•¸æ“š
â”‚   â”œâ”€â”€ daily/                   # æŒ‰æ—¥æœŸåˆ†çµ„
â”‚   â”‚   â”œâ”€â”€ 2025-06-08/
â”‚   â”‚   â”‚   â”œâ”€â”€ gaia_testing/
â”‚   â”‚   â”‚   â”œâ”€â”€ mcp_management/
â”‚   â”‚   â”‚   â””â”€â”€ data_analysis/
â”‚   â”‚   â””â”€â”€ 2025-06-09/
â”‚   â””â”€â”€ sessions/                # æŒ‰æœƒè©±åˆ†çµ„
â”‚       â”œâ”€â”€ session_001/
â”‚       â””â”€â”€ session_002/
â”œâ”€â”€ processed_data/              # è™•ç†å¾Œæ•¸æ“š
â”‚   â”œâ”€â”€ categorized/             # æŒ‰åˆ†é¡æ•´ç†
â”‚   â”‚   â”œâ”€â”€ high_value/
â”‚   â”‚   â”œâ”€â”€ medium_value/
â”‚   â”‚   â””â”€â”€ learning_patterns/
â”‚   â”œâ”€â”€ aggregated/              # èšåˆçµ±è¨ˆ
â”‚   â””â”€â”€ cleaned/                 # æ¸…ç†å¾Œæ•¸æ“š
â”œâ”€â”€ training_sets/               # è¨“ç·´é›†
â”‚   â”œâ”€â”€ gaia_optimization/
â”‚   â”œâ”€â”€ tool_selection/
â”‚   â”œâ”€â”€ error_prevention/
â”‚   â””â”€â”€ workflow_optimization/
â””â”€â”€ metadata/                    # å…ƒæ•¸æ“š
    â”œâ”€â”€ schemas/
    â”œâ”€â”€ statistics/
    â””â”€â”€ quality_reports/
```

### 2. æ•¸æ“šåº«è¨­è¨ˆ

```sql
-- CLIäº¤äº’ä¸»è¡¨
CREATE TABLE cli_interactions (
    id BIGSERIAL PRIMARY KEY,
    session_id VARCHAR(64) NOT NULL,
    timestamp TIMESTAMP WITH TIME ZONE NOT NULL,
    user_hash VARCHAR(64), -- åŒ¿ååŒ–ç”¨æˆ¶æ¨™è­˜
    
    -- è¼¸å…¥ä¿¡æ¯
    command TEXT NOT NULL,
    arguments JSONB,
    context JSONB,
    
    -- åˆ†é¡ä¿¡æ¯
    task_type VARCHAR(32) NOT NULL,
    task_subcategory VARCHAR(64),
    complexity_level VARCHAR(16) NOT NULL,
    
    -- åŸ·è¡Œä¿¡æ¯
    execution_time FLOAT,
    tools_used TEXT[],
    mcp_adapters TEXT[],
    
    -- çµæœä¿¡æ¯
    result_status VARCHAR(32) NOT NULL,
    output_data JSONB,
    error_info JSONB,
    
    -- è³ªé‡è©•ä¼°
    accuracy_score FLOAT,
    user_satisfaction INTEGER CHECK (user_satisfaction BETWEEN 1 AND 5),
    learning_value VARCHAR(16) NOT NULL,
    
    -- å…ƒæ•¸æ“š
    system_version VARCHAR(32),
    environment_info JSONB,
    
    -- ç´¢å¼•
    INDEX idx_timestamp (timestamp),
    INDEX idx_task_type (task_type),
    INDEX idx_learning_value (learning_value),
    INDEX idx_result_status (result_status)
);

-- å·¥å…·ä½¿ç”¨çµ±è¨ˆè¡¨
CREATE TABLE tool_usage_stats (
    id BIGSERIAL PRIMARY KEY,
    tool_name VARCHAR(64) NOT NULL,
    task_type VARCHAR(32) NOT NULL,
    usage_count INTEGER DEFAULT 0,
    success_count INTEGER DEFAULT 0,
    avg_execution_time FLOAT,
    avg_accuracy FLOAT,
    last_updated TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- å­¸ç¿’æ¨¡å¼è¡¨
CREATE TABLE learning_patterns (
    id BIGSERIAL PRIMARY KEY,
    pattern_type VARCHAR(32) NOT NULL,
    pattern_data JSONB NOT NULL,
    confidence_score FLOAT,
    usage_frequency INTEGER DEFAULT 0,
    effectiveness_score FLOAT,
    discovered_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);
```

---

## ğŸ”„ æ•¸æ“šæ”¶é›†æµç¨‹

### 1. å¯¦æ™‚æ•¸æ“šæ”¶é›†

```python
class CLIDataCollector:
    """CLIæ•¸æ“šæ”¶é›†å™¨"""
    
    def __init__(self):
        self.session_id = self.generate_session_id()
        self.data_buffer = []
        
    def collect_interaction(self, 
                          command: str,
                          arguments: Dict[str, Any],
                          context: Dict[str, Any]) -> str:
        """æ”¶é›†CLIäº¤äº’æ•¸æ“š"""
        
        interaction_id = self.generate_interaction_id()
        
        # å‰µå»ºæ•¸æ“šè¨˜éŒ„
        interaction_data = CLIInteractionData(
            session_id=self.session_id,
            timestamp=datetime.now(),
            command=command,
            arguments=arguments,
            context=context,
            task_type=self.classify_task_type(command, arguments),
            complexity_level=self.assess_complexity(command, arguments),
            system_version=self.get_system_version(),
            environment_info=self.get_environment_info()
        )
        
        # ç·©å­˜æ•¸æ“š
        self.data_buffer.append(interaction_data)
        
        return interaction_id
    
    def update_result(self,
                     interaction_id: str,
                     result_status: ResultStatus,
                     output_data: Dict[str, Any],
                     execution_time: float,
                     tools_used: List[str],
                     error_info: Optional[Dict[str, Any]] = None):
        """æ›´æ–°åŸ·è¡Œçµæœ"""
        
        # æ‰¾åˆ°å°æ‡‰çš„äº¤äº’è¨˜éŒ„ä¸¦æ›´æ–°
        for interaction in self.data_buffer:
            if interaction.interaction_id == interaction_id:
                interaction.result_status = result_status
                interaction.output_data = output_data
                interaction.execution_time = execution_time
                interaction.tools_used = tools_used
                interaction.error_info = error_info
                interaction.learning_value = self.assess_learning_value(interaction)
                break
    
    def flush_to_storage(self):
        """å°‡ç·©å­˜æ•¸æ“šå¯«å…¥å­˜å„²"""
        for interaction in self.data_buffer:
            self.store_interaction(interaction)
        self.data_buffer.clear()
```

### 2. æ•¸æ“šåˆ†é¡é‚è¼¯

```python
class CLIDataClassifier:
    """CLIæ•¸æ“šåˆ†é¡å™¨"""
    
    def classify_task_type(self, command: str, arguments: Dict[str, Any]) -> TaskType:
        """åˆ†é¡ä»»å‹™é¡å‹"""
        
        if "--gaia" in arguments or "gaia" in command.lower():
            return TaskType.GAIA_TESTING
        elif "--list" in arguments or "list" in command:
            return TaskType.MCP_MANAGEMENT
        elif any(keyword in command.lower() for keyword in ["analyze", "data", "file"]):
            return TaskType.DATA_ANALYSIS
        elif any(keyword in command.lower() for keyword in ["generate", "code", "script"]):
            return TaskType.CODE_GENERATION
        else:
            return TaskType.SYSTEM_OPERATION
    
    def assess_complexity(self, command: str, arguments: Dict[str, Any]) -> ComplexityLevel:
        """è©•ä¼°è¤‡é›œåº¦"""
        
        arg_count = len(arguments)
        command_length = len(command.split())
        
        if arg_count <= 1 and command_length <= 2:
            return ComplexityLevel.SIMPLE
        elif arg_count <= 3 and command_length <= 5:
            return ComplexityLevel.MODERATE
        elif arg_count <= 6 and command_length <= 10:
            return ComplexityLevel.COMPLEX
        else:
            return ComplexityLevel.EXPERT
    
    def assess_learning_value(self, interaction: CLIInteractionData) -> LearningValue:
        """è©•ä¼°å­¸ç¿’åƒ¹å€¼"""
        
        # åŸºæ–¼å¤šå€‹å› ç´ è©•ä¼°
        factors = {
            "novelty": self.assess_novelty(interaction),
            "success": self.assess_success(interaction),
            "complexity": self.assess_complexity_value(interaction),
            "frequency": self.assess_frequency(interaction)
        }
        
        # ç¶œåˆè©•åˆ†
        total_score = sum(factors.values()) / len(factors)
        
        if total_score >= 0.8:
            return LearningValue.HIGH
        elif total_score >= 0.6:
            return LearningValue.MEDIUM
        elif total_score >= 0.3:
            return LearningValue.LOW
        else:
            return LearningValue.NEGATIVE
```

---

## ğŸ“ˆ æ•¸æ“šè³ªé‡æ§åˆ¶

### 1. æ•¸æ“šé©—è­‰è¦å‰‡

```python
class CLIDataValidator:
    """CLIæ•¸æ“šé©—è­‰å™¨"""
    
    def validate_interaction(self, interaction: CLIInteractionData) -> bool:
        """é©—è­‰äº¤äº’æ•¸æ“š"""
        
        checks = [
            self.check_required_fields(interaction),
            self.check_data_types(interaction),
            self.check_value_ranges(interaction),
            self.check_consistency(interaction),
            self.check_privacy_compliance(interaction)
        ]
        
        return all(checks)
    
    def check_privacy_compliance(self, interaction: CLIInteractionData) -> bool:
        """æª¢æŸ¥éš±ç§åˆè¦æ€§"""
        
        # ç¢ºä¿æ²’æœ‰æ•æ„Ÿä¿¡æ¯
        sensitive_patterns = [
            r'\b\d{4}-\d{4}-\d{4}-\d{4}\b',  # ä¿¡ç”¨å¡è™Ÿ
            r'\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b',  # éƒµç®±
            r'\b\d{3}-\d{2}-\d{4}\b',  # SSN
        ]
        
        text_content = str(interaction.command) + str(interaction.arguments)
        
        for pattern in sensitive_patterns:
            if re.search(pattern, text_content):
                return False
        
        return True
```

### 2. æ•¸æ“šæ¸…ç†æµç¨‹

```python
class CLIDataCleaner:
    """CLIæ•¸æ“šæ¸…ç†å™¨"""
    
    def clean_interaction_data(self, raw_data: List[CLIInteractionData]) -> List[CLIInteractionData]:
        """æ¸…ç†äº¤äº’æ•¸æ“š"""
        
        cleaned_data = []
        
        for interaction in raw_data:
            # åŒ¿ååŒ–è™•ç†
            interaction = self.anonymize_data(interaction)
            
            # æ¨™æº–åŒ–æ ¼å¼
            interaction = self.standardize_format(interaction)
            
            # ç§»é™¤æ•æ„Ÿä¿¡æ¯
            interaction = self.remove_sensitive_info(interaction)
            
            # é©—è­‰æ•¸æ“šè³ªé‡
            if self.validate_quality(interaction):
                cleaned_data.append(interaction)
        
        return cleaned_data
    
    def anonymize_data(self, interaction: CLIInteractionData) -> CLIInteractionData:
        """åŒ¿ååŒ–æ•¸æ“š"""
        
        # ç§»é™¤æˆ–å“ˆå¸ŒåŒ–ç”¨æˆ¶æ¨™è­˜
        if interaction.user_id:
            interaction.user_id = hashlib.sha256(interaction.user_id.encode()).hexdigest()[:16]
        
        # ç§»é™¤IPåœ°å€ç­‰æ•æ„Ÿä¿¡æ¯
        if 'ip_address' in interaction.environment_info:
            del interaction.environment_info['ip_address']
        
        return interaction
```

---

## ğŸ¯ è¨“ç·´æ•¸æ“šç”Ÿæˆ

### 1. è¨“ç·´é›†æ§‹å»º

```python
class TrainingDataBuilder:
    """è¨“ç·´æ•¸æ“šæ§‹å»ºå™¨"""
    
    def build_gaia_optimization_dataset(self) -> Dict[str, Any]:
        """æ§‹å»ºGAIAå„ªåŒ–è¨“ç·´é›†"""
        
        # æŸ¥è©¢GAIAç›¸é—œçš„é«˜åƒ¹å€¼äº¤äº’
        gaia_interactions = self.query_interactions(
            task_type=TaskType.GAIA_TESTING,
            learning_value=[LearningValue.HIGH, LearningValue.MEDIUM],
            result_status=[ResultStatus.SUCCESS_PERFECT, ResultStatus.SUCCESS_PARTIAL]
        )
        
        # æ§‹å»ºè¨“ç·´æ¨£æœ¬
        training_samples = []
        for interaction in gaia_interactions:
            sample = {
                "input": {
                    "question_type": self.extract_question_type(interaction),
                    "complexity": interaction.complexity_level.value,
                    "context": interaction.context
                },
                "optimal_strategy": {
                    "tools": interaction.tools_used,
                    "sequence": self.extract_tool_sequence(interaction),
                    "parameters": self.extract_parameters(interaction)
                },
                "expected_outcome": {
                    "accuracy": interaction.accuracy_score,
                    "execution_time": interaction.execution_time,
                    "success_probability": self.calculate_success_probability(interaction)
                }
            }
            training_samples.append(sample)
        
        return {
            "dataset_name": "gaia_optimization",
            "version": "1.0",
            "samples": training_samples,
            "metadata": {
                "total_samples": len(training_samples),
                "collection_period": self.get_collection_period(),
                "quality_score": self.calculate_dataset_quality(training_samples)
            }
        }
    
    def build_tool_selection_dataset(self) -> Dict[str, Any]:
        """æ§‹å»ºå·¥å…·é¸æ“‡è¨“ç·´é›†"""
        
        # åˆ†æå·¥å…·ä½¿ç”¨æ¨¡å¼
        tool_patterns = self.analyze_tool_patterns()
        
        # æ§‹å»ºå·¥å…·é¸æ“‡æ¨£æœ¬
        selection_samples = []
        for pattern in tool_patterns:
            sample = {
                "task_description": pattern["task_description"],
                "available_tools": pattern["available_tools"],
                "optimal_selection": pattern["best_tools"],
                "performance_metrics": pattern["metrics"]
            }
            selection_samples.append(sample)
        
        return {
            "dataset_name": "tool_selection",
            "version": "1.0", 
            "samples": selection_samples
        }
```

---

## ğŸ”„ æŒçºŒå­¸ç¿’é›†æˆ

### 1. RL-SRTé›†æˆ

```python
class CLIDataRLIntegration:
    """CLIæ•¸æ“šå¼·åŒ–å­¸ç¿’é›†æˆ"""
    
    def __init__(self):
        self.rl_srt_adapter = self.get_rl_srt_adapter()
        
    def feed_to_rl_system(self, interaction_data: List[CLIInteractionData]):
        """å°‡CLIæ•¸æ“šé¤µçµ¦RLç³»çµ±"""
        
        # è½‰æ›ç‚ºRLè¨“ç·´æ ¼å¼
        rl_episodes = []
        for interaction in interaction_data:
            episode = {
                "state": self.extract_state(interaction),
                "action": self.extract_action(interaction),
                "reward": self.calculate_reward(interaction),
                "next_state": self.extract_next_state(interaction)
            }
            rl_episodes.append(episode)
        
        # é¤µçµ¦RL-SRTç³»çµ±
        self.rl_srt_adapter.train_from_episodes(rl_episodes)
    
    def calculate_reward(self, interaction: CLIInteractionData) -> float:
        """è¨ˆç®—çå‹µå€¼"""
        
        base_reward = 0.0
        
        # åŸºæ–¼çµæœç‹€æ…‹
        if interaction.result_status == ResultStatus.SUCCESS_PERFECT:
            base_reward += 1.0
        elif interaction.result_status == ResultStatus.SUCCESS_PARTIAL:
            base_reward += 0.7
        elif interaction.result_status == ResultStatus.SUCCESS_ACCEPTABLE:
            base_reward += 0.5
        else:
            base_reward -= 0.5
        
        # åŸºæ–¼æº–ç¢ºç‡
        if interaction.accuracy_score:
            base_reward += interaction.accuracy_score * 0.5
        
        # åŸºæ–¼åŸ·è¡Œæ•ˆç‡
        if interaction.execution_time:
            efficiency_bonus = max(0, (10 - interaction.execution_time) / 10 * 0.3)
            base_reward += efficiency_bonus
        
        # åŸºæ–¼ç”¨æˆ¶æ»¿æ„åº¦
        if interaction.user_satisfaction:
            satisfaction_bonus = (interaction.user_satisfaction - 3) / 2 * 0.2
            base_reward += satisfaction_bonus
        
        return base_reward
```

---

## ğŸ“Š ç›£æ§å’Œåˆ†æ

### 1. æ•¸æ“šè³ªé‡ç›£æ§

```python
class CLIDataMonitor:
    """CLIæ•¸æ“šç›£æ§å™¨"""
    
    def generate_quality_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæ•¸æ“šè³ªé‡å ±å‘Š"""
        
        return {
            "collection_stats": {
                "total_interactions": self.count_total_interactions(),
                "daily_average": self.calculate_daily_average(),
                "task_type_distribution": self.get_task_distribution(),
                "complexity_distribution": self.get_complexity_distribution()
            },
            "quality_metrics": {
                "data_completeness": self.calculate_completeness(),
                "accuracy_scores": self.get_accuracy_distribution(),
                "error_rates": self.calculate_error_rates(),
                "learning_value_distribution": self.get_learning_value_distribution()
            },
            "training_readiness": {
                "high_value_samples": self.count_high_value_samples(),
                "balanced_distribution": self.check_balance(),
                "sufficient_volume": self.check_volume_sufficiency()
            }
        }
```

é€™å€‹è¨­è¨ˆç¢ºä¿äº†CLIæ•¸æ“šèƒ½å¤ æŒ‰ç…§çµæ§‹åŒ–çš„æ–¹å¼æ”¶é›†ã€åˆ†é¡å’Œå­˜å„²ï¼Œç‚ºå¾ŒçºŒçš„è¨“ç·´å’Œå„ªåŒ–æä¾›é«˜è³ªé‡çš„æ•¸æ“šåŸºç¤ã€‚

