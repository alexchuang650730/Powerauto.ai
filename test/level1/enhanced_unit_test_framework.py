#!/usr/bin/env python3
"""
Level 1 å–®å…ƒæ¸¬è©¦æ¡†æ¶
åŸºç¤å±¤ï¼šå–®å…ƒæ¸¬è©¦ + ä»£ç¢¼è³ªé‡

ä¸»è¦åŠŸèƒ½ï¼š
- é©é…å™¨å–®å…ƒæ¸¬è©¦
- ä»£ç¢¼è³ªé‡æª¢æŸ¥
- æ–¹æ³•ç´šåˆ¥æ¸¬è©¦
- åŸºç¤åŠŸèƒ½é©—è­‰
"""

import sys
import os
import time
import json
import logging
from typing import Dict, Any, List, Optional, Union
from pathlib import Path
from datetime import datetime

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

# å°å…¥æ¨™æº–åŒ–æ¥å£
from test.standardized_test_interface import BaseTestFramework, TestResult, TestStatus, TestSeverity
from test.optimized_module_importer import get_safe_importer

logger = logging.getLogger(__name__)

class Level1UnitTestFramework(BaseTestFramework):
    """Level 1 å–®å…ƒæ¸¬è©¦æ¡†æ¶"""
    
    def __init__(self):
        super().__init__(
            name="Level1_UnitTest",
            description="åŸºç¤å±¤å–®å…ƒæ¸¬è©¦å’Œä»£ç¢¼è³ªé‡æª¢æŸ¥"
        )
        
        self.importer = get_safe_importer()
        
        # æ¸¬è©¦é…ç½®
        self.test_config = {
            "timeout": 30.0,  # å–®å€‹æ¸¬è©¦è¶…æ™‚æ™‚é–“
            "required_methods": ["get_name", "get_capabilities"],
            "optional_methods": ["process", "get_version", "get_description"],
            "quality_checks": ["naming", "documentation", "error_handling"]
        }
    
    def run_tests(self, adapter_name: Optional[str] = None) -> List[TestResult]:
        """é‹è¡ŒLevel 1å–®å…ƒæ¸¬è©¦"""
        self.logger.info("é–‹å§‹Level 1å–®å…ƒæ¸¬è©¦...")
        self.test_results.clear()
        
        # ç²å–é©é…å™¨åˆ—è¡¨
        adapters = self.get_adapters()
        
        if not adapters:
            self.logger.warning("æœªæ‰¾åˆ°ä»»ä½•é©é…å™¨")
            return []
        
        # éæ¿¾é©é…å™¨
        if adapter_name:
            adapters = [(name, instance) for name, instance in adapters if name == adapter_name]
        
        self.logger.info(f"æ¸¬è©¦ {len(adapters)} å€‹é©é…å™¨")
        
        # é‹è¡Œæ¸¬è©¦
        for name, instance in adapters:
            self._test_adapter_unit(name, instance)
        
        self.logger.info(f"Level 1æ¸¬è©¦å®Œæˆï¼Œå…± {len(self.test_results)} å€‹æ¸¬è©¦çµæœ")
        return self.test_results
    
    def _test_adapter_unit(self, adapter_name: str, adapter_instance: Any):
        """æ¸¬è©¦å–®å€‹é©é…å™¨çš„å–®å…ƒåŠŸèƒ½"""
        self.logger.debug(f"æ¸¬è©¦é©é…å™¨å–®å…ƒåŠŸèƒ½: {adapter_name}")
        
        # 1. åŸºç¤æ–¹æ³•æ¸¬è©¦
        self._test_basic_methods(adapter_name, adapter_instance)
        
        # 2. æ–¹æ³•èª¿ç”¨æ¸¬è©¦
        self._test_method_calls(adapter_name, adapter_instance)
        
        # 3. ä»£ç¢¼è³ªé‡æ¸¬è©¦
        self._test_code_quality(adapter_name, adapter_instance)
        
        # 4. éŒ¯èª¤è™•ç†æ¸¬è©¦
        self._test_error_handling(adapter_name, adapter_instance)
    
    def _test_basic_methods(self, adapter_name: str, adapter_instance: Any):
        """æ¸¬è©¦åŸºç¤æ–¹æ³•å­˜åœ¨æ€§"""
        start_time = time.time()
        
        required_methods = self.test_config["required_methods"]
        optional_methods = self.test_config["optional_methods"]
        
        # æª¢æŸ¥å¿…éœ€æ–¹æ³•
        missing_required = []
        for method_name in required_methods:
            if not hasattr(adapter_instance, method_name):
                missing_required.append(method_name)
        
        # æª¢æŸ¥å¯é¸æ–¹æ³•
        available_optional = []
        for method_name in optional_methods:
            if hasattr(adapter_instance, method_name):
                available_optional.append(method_name)
        
        # è¨ˆç®—åˆ†æ•¸
        required_score = (len(required_methods) - len(missing_required)) / len(required_methods) * 100
        optional_score = len(available_optional) / len(optional_methods) * 100
        overall_score = required_score * 0.8 + optional_score * 0.2
        
        # å‰µå»ºæ¸¬è©¦çµæœ
        passed = len(missing_required) == 0
        message = f"å¿…éœ€æ–¹æ³•: {len(required_methods) - len(missing_required)}/{len(required_methods)}, å¯é¸æ–¹æ³•: {len(available_optional)}/{len(optional_methods)}"
        
        if missing_required:
            message += f", ç¼ºå¤±: {', '.join(missing_required)}"
        
        execution_time = time.time() - start_time
        
        result = self.create_test_result(
            test_name="test_unit_basic_methods",
            adapter_name=adapter_name,
            passed=passed,
            score=overall_score,
            execution_time=execution_time,
            message=message,
            details={
                "required_methods": required_methods,
                "missing_required": missing_required,
                "available_optional": available_optional,
                "required_score": required_score,
                "optional_score": optional_score
            },
            severity=TestSeverity.HIGH if not passed else TestSeverity.LOW
        )
        
        self.add_test_result(result)
    
    def _test_method_calls(self, adapter_name: str, adapter_instance: Any):
        """æ¸¬è©¦æ–¹æ³•èª¿ç”¨"""
        start_time = time.time()
        
        test_results = {}
        total_score = 0
        test_count = 0
        
        # æ¸¬è©¦get_nameæ–¹æ³•
        if hasattr(adapter_instance, "get_name"):
            result = self.test_adapter_method(adapter_instance, "get_name")
            test_results["get_name"] = result
            
            if result["success"]:
                name_value = result["result"]
                if isinstance(name_value, str) and len(name_value) > 0:
                    total_score += 100
                else:
                    total_score += 50
            test_count += 1
        
        # æ¸¬è©¦get_capabilitiesæ–¹æ³•
        if hasattr(adapter_instance, "get_capabilities"):
            result = self.test_adapter_method(adapter_instance, "get_capabilities")
            test_results["get_capabilities"] = result
            
            if result["success"]:
                caps_value = result["result"]
                if isinstance(caps_value, (list, dict)) and len(caps_value) > 0:
                    total_score += 100
                elif isinstance(caps_value, (list, dict)):
                    total_score += 70
                else:
                    total_score += 30
            test_count += 1
        
        # æ¸¬è©¦processæ–¹æ³•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(adapter_instance, "process"):
            test_data = {"test": "unit_test_data", "timestamp": datetime.now().isoformat()}
            result = self.test_adapter_method(adapter_instance, "process", test_data)
            test_results["process"] = result
            
            if result["success"]:
                total_score += 100
            else:
                total_score += 20  # è‡³å°‘æ–¹æ³•å­˜åœ¨
            test_count += 1
        
        # è¨ˆç®—å¹³å‡åˆ†æ•¸
        average_score = total_score / test_count if test_count > 0 else 0
        
        # åˆ¤æ–·æ˜¯å¦é€šé
        passed = all(r["success"] for r in test_results.values())
        
        execution_time = time.time() - start_time
        
        # å‰µå»ºæ¶ˆæ¯
        success_count = sum(1 for r in test_results.values() if r["success"])
        message = f"æ–¹æ³•èª¿ç”¨æ¸¬è©¦: {success_count}/{len(test_results)} æˆåŠŸ"
        
        result = self.create_test_result(
            test_name="test_unit_method_calls",
            adapter_name=adapter_name,
            passed=passed,
            score=average_score,
            execution_time=execution_time,
            message=message,
            details={
                "test_results": test_results,
                "success_count": success_count,
                "total_tests": len(test_results)
            },
            severity=TestSeverity.MEDIUM
        )
        
        self.add_test_result(result)
    
    def _test_code_quality(self, adapter_name: str, adapter_instance: Any):
        """æ¸¬è©¦ä»£ç¢¼è³ªé‡"""
        start_time = time.time()
        
        quality_scores = {}
        
        # 1. å‘½åè¦ç¯„æª¢æŸ¥
        naming_score = self._check_naming_convention(adapter_instance)
        quality_scores["naming"] = naming_score
        
        # 2. æ–‡æª”æª¢æŸ¥
        documentation_score = self._check_documentation(adapter_instance)
        quality_scores["documentation"] = documentation_score
        
        # 3. é¡çµæ§‹æª¢æŸ¥
        structure_score = self._check_class_structure(adapter_instance)
        quality_scores["structure"] = structure_score
        
        # è¨ˆç®—ç¸½é«”è³ªé‡åˆ†æ•¸
        overall_score = sum(quality_scores.values()) / len(quality_scores)
        
        # åˆ¤æ–·æ˜¯å¦é€šéï¼ˆè³ªé‡åˆ†æ•¸ >= 60ï¼‰
        passed = overall_score >= 60
        
        execution_time = time.time() - start_time
        
        message = f"ä»£ç¢¼è³ªé‡åˆ†æ•¸: {overall_score:.1f} (å‘½å: {naming_score:.1f}, æ–‡æª”: {documentation_score:.1f}, çµæ§‹: {structure_score:.1f})"
        
        result = self.create_test_result(
            test_name="test_unit_code_quality",
            adapter_name=adapter_name,
            passed=passed,
            score=overall_score,
            execution_time=execution_time,
            message=message,
            details=quality_scores,
            severity=TestSeverity.LOW
        )
        
        self.add_test_result(result)
    
    def _check_naming_convention(self, adapter_instance: Any) -> float:
        """æª¢æŸ¥å‘½åè¦ç¯„"""
        score = 0
        checks = 0
        
        # æª¢æŸ¥é¡å
        class_name = adapter_instance.__class__.__name__
        if class_name[0].isupper():  # é¦–å­—æ¯å¤§å¯«
            score += 25
        checks += 1
        
        # æª¢æŸ¥æ–¹æ³•å
        method_names = [name for name in dir(adapter_instance) 
                       if callable(getattr(adapter_instance, name)) and not name.startswith('_')]
        
        if method_names:
            snake_case_count = sum(1 for name in method_names if '_' in name or name.islower())
            score += (snake_case_count / len(method_names)) * 25
        checks += 1
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æè¿°æ€§åç¨±
        if any(keyword in class_name.lower() for keyword in ['adapter', 'mcp', 'tool', 'engine']):
            score += 25
        checks += 1
        
        # æª¢æŸ¥æ–¹æ³•åæ˜¯å¦æè¿°æ€§
        descriptive_methods = ['get_name', 'get_capabilities', 'process', 'initialize']
        found_descriptive = sum(1 for method in descriptive_methods if hasattr(adapter_instance, method))
        score += (found_descriptive / len(descriptive_methods)) * 25
        checks += 1
        
        return score
    
    def _check_documentation(self, adapter_instance: Any) -> float:
        """æª¢æŸ¥æ–‡æª”è³ªé‡"""
        score = 0
        
        # æª¢æŸ¥é¡æ–‡æª”å­—ç¬¦ä¸²
        class_doc = adapter_instance.__class__.__doc__
        if class_doc and len(class_doc.strip()) > 10:
            score += 40
        elif class_doc:
            score += 20
        
        # æª¢æŸ¥æ–¹æ³•æ–‡æª”å­—ç¬¦ä¸²
        methods_with_docs = 0
        total_methods = 0
        
        for name in dir(adapter_instance):
            if callable(getattr(adapter_instance, name)) and not name.startswith('_'):
                total_methods += 1
                method = getattr(adapter_instance, name)
                if hasattr(method, '__doc__') and method.__doc__ and len(method.__doc__.strip()) > 5:
                    methods_with_docs += 1
        
        if total_methods > 0:
            doc_ratio = methods_with_docs / total_methods
            score += doc_ratio * 60
        
        return score
    
    def _check_class_structure(self, adapter_instance: Any) -> float:
        """æª¢æŸ¥é¡çµæ§‹"""
        score = 0
        
        # æª¢æŸ¥æ˜¯å¦æœ‰__init__æ–¹æ³•
        if hasattr(adapter_instance, '__init__'):
            score += 20
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„æ–¹æ³•
        required_methods = ['get_name', 'get_capabilities']
        found_required = sum(1 for method in required_methods if hasattr(adapter_instance, method))
        score += (found_required / len(required_methods)) * 40
        
        # æª¢æŸ¥æ˜¯å¦æœ‰è™•ç†æ–¹æ³•
        if hasattr(adapter_instance, 'process'):
            score += 20
        
        # æª¢æŸ¥æ–¹æ³•æ•¸é‡ï¼ˆä¸æ‡‰è©²å¤ªå°‘æˆ–å¤ªå¤šï¼‰
        public_methods = [name for name in dir(adapter_instance) 
                         if callable(getattr(adapter_instance, name)) and not name.startswith('_')]
        
        method_count = len(public_methods)
        if 3 <= method_count <= 15:  # åˆç†çš„æ–¹æ³•æ•¸é‡
            score += 20
        elif method_count > 0:
            score += 10
        
        return score
    
    def _test_error_handling(self, adapter_name: str, adapter_instance: Any):
        """æ¸¬è©¦éŒ¯èª¤è™•ç†"""
        start_time = time.time()
        
        error_tests = {}
        total_score = 0
        
        # æ¸¬è©¦ç„¡æ•ˆåƒæ•¸è™•ç†
        if hasattr(adapter_instance, "process"):
            # æ¸¬è©¦Noneåƒæ•¸
            try:
                result = adapter_instance.process(None)
                error_tests["none_input"] = {"handled": True, "result": result}
                total_score += 25
            except Exception as e:
                error_tests["none_input"] = {"handled": True, "error": str(e)}
                total_score += 20  # æ‹‹å‡ºç•°å¸¸ä¹Ÿæ˜¯ä¸€ç¨®è™•ç†æ–¹å¼
        
        # æ¸¬è©¦ç©ºå­—å…¸åƒæ•¸
        if hasattr(adapter_instance, "process"):
            try:
                result = adapter_instance.process({})
                error_tests["empty_dict"] = {"handled": True, "result": result}
                total_score += 25
            except Exception as e:
                error_tests["empty_dict"] = {"handled": True, "error": str(e)}
                total_score += 20
        
        # æ¸¬è©¦ç„¡æ•ˆé¡å‹åƒæ•¸
        if hasattr(adapter_instance, "process"):
            try:
                result = adapter_instance.process("invalid_type")
                error_tests["invalid_type"] = {"handled": True, "result": result}
                total_score += 25
            except Exception as e:
                error_tests["invalid_type"] = {"handled": True, "error": str(e)}
                total_score += 20
        
        # å¦‚æœæ²’æœ‰processæ–¹æ³•ï¼Œçµ¦äºˆåŸºç¤åˆ†æ•¸
        if not hasattr(adapter_instance, "process"):
            total_score = 75  # åŸºç¤åˆ†æ•¸
            error_tests["no_process_method"] = {"note": "é©é…å™¨æ²’æœ‰processæ–¹æ³•"}
        
        # æ¸¬è©¦æ–¹æ³•èª¿ç”¨éŒ¯èª¤è™•ç†
        if hasattr(adapter_instance, "get_name"):
            try:
                # å˜—è©¦èª¿ç”¨å¯èƒ½å‡ºéŒ¯çš„æ–¹æ³•
                name = adapter_instance.get_name()
                if name is not None:
                    total_score += 25
            except Exception as e:
                error_tests["get_name_error"] = {"error": str(e)}
                total_score += 10
        
        passed = total_score >= 60
        execution_time = time.time() - start_time
        
        message = f"éŒ¯èª¤è™•ç†æ¸¬è©¦åˆ†æ•¸: {total_score:.1f}"
        
        result = self.create_test_result(
            test_name="test_unit_error_handling",
            adapter_name=adapter_name,
            passed=passed,
            score=total_score,
            execution_time=execution_time,
            message=message,
            details=error_tests,
            severity=TestSeverity.MEDIUM
        )
        
        self.add_test_result(result)

def run_level1_tests(adapter_name: Optional[str] = None) -> List[TestResult]:
    """é‹è¡ŒLevel 1æ¸¬è©¦çš„ä¾¿æ·å‡½æ•¸"""
    framework = Level1UnitTestFramework()
    return framework.run_tests(adapter_name)

if __name__ == "__main__":
    # é‹è¡ŒLevel 1æ¸¬è©¦
    print("ğŸ§ª é–‹å§‹Level 1å–®å…ƒæ¸¬è©¦...")
    
    framework = Level1UnitTestFramework()
    results = framework.run_tests()
    
    # é¡¯ç¤ºçµæœ
    summary = framework.get_test_summary()
    print(f"ğŸ“Š æ¸¬è©¦å®Œæˆ:")
    print(f"   ç¸½æ¸¬è©¦æ•¸: {summary['total_tests']}")
    print(f"   é€šéæ¸¬è©¦: {summary['passed_tests']}")
    print(f"   å¤±æ•—æ¸¬è©¦: {summary['failed_tests']}")
    print(f"   é€šéç‡: {summary['pass_rate']:.1%}")
    print(f"   ç¸½é«”åˆ†æ•¸: {summary['overall_score']:.1f}")
    print(f"   åŸ·è¡Œæ™‚é–“: {summary['total_time']:.2f}ç§’")
    
    # ä¿å­˜çµæœ
    framework.save_results("test/level1")
    print("ğŸ“„ æ¸¬è©¦å ±å‘Šå·²ä¿å­˜åˆ° test/level1/")
    
    # ç”Ÿæˆç°¡è¦å ±å‘Š
    report = framework.generate_report()
    print("\nğŸ“‹ æ¸¬è©¦å ±å‘Šé è¦½:")
    print(report[:1000] + "..." if len(report) > 1000 else report)

