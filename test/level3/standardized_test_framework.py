#!/usr/bin/env python3
"""
MCPæ¨™æº–åŒ–æ¸¬è©¦æ¡†æ¶
æä¾›çµ±ä¸€çš„MCPé©é…å™¨æ¨™æº–åŒ–æ¸¬è©¦å’Œé©—è­‰åŠŸèƒ½

åŒ…æ‹¬ï¼š
- æ¥å£æ¨™æº–åŒ–æ¸¬è©¦
- éŸ¿æ‡‰æ ¼å¼æ¨™æº–åŒ–
- éŒ¯èª¤è™•ç†æ¨™æº–åŒ–
- èƒ½åŠ›è²æ˜æ¨™æº–åŒ–
- æ–‡æª”æ¨™æº–åŒ–
"""

import sys
import os
import json
import time
import logging
import inspect
import importlib
from typing import Dict, Any, List, Optional, Union, Callable
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, asdict
from abc import ABC, abstractmethod

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°Pythonè·¯å¾‘
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

logger = logging.getLogger(__name__)

@dataclass
class StandardTestResult:
    """æ¨™æº–åŒ–æ¸¬è©¦çµæœ"""
    test_name: str
    adapter_name: str
    passed: bool
    score: float
    errors: List[str]
    warnings: List[str]
    details: Dict[str, Any]
    execution_time: float

@dataclass
class MCPStandard:
    """MCPæ¨™æº–å®šç¾©"""
    interface_methods: List[str]
    response_format: Dict[str, Any]
    error_codes: Dict[int, str]
    capability_format: Dict[str, Any]
    documentation_requirements: List[str]

class MCPStandardizedTestFramework:
    """MCPæ¨™æº–åŒ–æ¸¬è©¦æ¡†æ¶"""
    
    def __init__(self):
        self.test_results = []
        self.standards = self._load_mcp_standards()
        self.adapters_registry = {}
        
        # æ¸¬è©¦çµ±è¨ˆ
        self.stats = {
            "total_adapters": 0,
            "tested_adapters": 0,
            "passed_adapters": 0,
            "failed_adapters": 0,
            "overall_compliance": 0.0,
            "test_categories": {
                "interface_standardization": {"passed": 0, "total": 0},
                "response_format": {"passed": 0, "total": 0},
                "error_handling": {"passed": 0, "total": 0},
                "capability_declaration": {"passed": 0, "total": 0},
                "documentation": {"passed": 0, "total": 0}
            }
        }
    
    def _load_mcp_standards(self) -> MCPStandard:
        """è¼‰å…¥MCPæ¨™æº–å®šç¾©"""
        return MCPStandard(
            interface_methods=[
                "process",
                "get_capabilities", 
                "get_status",
                "initialize",
                "cleanup"
            ],
            response_format={
                "status": str,
                "data": [dict, list, str, int, float, bool, type(None)],
                "message": str,
                "metadata": dict,
                "timestamp": str
            },
            error_codes={
                -32700: "Parse error",
                -32600: "Invalid Request", 
                -32601: "Method not found",
                -32602: "Invalid params",
                -32603: "Internal error",
                -32000: "Server error"
            },
            capability_format={
                "name": str,
                "version": str,
                "description": str,
                "capabilities": list,
                "supported_operations": list,
                "metadata": dict
            },
            documentation_requirements=[
                "README.md",
                "API documentation",
                "Usage examples",
                "Error handling guide"
            ]
        )
    
    def discover_adapters(self) -> Dict[str, Any]:
        """ç™¼ç¾æ‰€æœ‰MCPé©é…å™¨"""
        adapters = {}
        
        try:
            # å¾è¨»å†Šè¡¨ç™¼ç¾é©é…å™¨
            from mcptool.adapters.core.safe_mcp_registry import SafeMCPRegistry
            registry = SafeMCPRegistry()
            registered_adapters = registry.list_adapters()
            
            for adapter_name, adapter_info in registered_adapters.items():
                adapters[adapter_name] = {
                    "name": adapter_name,
                    "type": adapter_info.get("type", "unknown"),
                    "instance": adapter_info.get("instance"),
                    "metadata": adapter_info.get("metadata", {})
                }
                
        except Exception as e:
            logger.warning(f"ç„¡æ³•å¾è¨»å†Šè¡¨ç™¼ç¾é©é…å™¨: {e}")
        
        # å¾æ–‡ä»¶ç³»çµ±ç™¼ç¾é©é…å™¨
        adapters_dir = project_root / "mcptool" / "adapters"
        if adapters_dir.exists():
            for adapter_file in adapters_dir.rglob("*_mcp.py"):
                adapter_name = adapter_file.stem
                if adapter_name not in adapters:
                    adapters[adapter_name] = {
                        "name": adapter_name,
                        "type": "file_based",
                        "path": str(adapter_file),
                        "metadata": {}
                    }
        
        self.adapters_registry = adapters
        self.stats["total_adapters"] = len(adapters)
        
        logger.info(f"ç™¼ç¾ {len(adapters)} å€‹MCPé©é…å™¨")
        return adapters
    
    def test_interface_standardization(self, adapter_name: str, adapter_instance: Any) -> StandardTestResult:
        """æ¸¬è©¦æ¥å£æ¨™æº–åŒ–"""
        start_time = time.time()
        errors = []
        warnings = []
        details = {}
        
        # æª¢æŸ¥å¿…éœ€æ–¹æ³•
        missing_methods = []
        for method in self.standards.interface_methods:
            if not hasattr(adapter_instance, method):
                missing_methods.append(method)
        
        if missing_methods:
            errors.append(f"ç¼ºå°‘å¿…éœ€æ–¹æ³•: {missing_methods}")
        
        # æª¢æŸ¥æ–¹æ³•ç°½å
        method_signatures = {}
        for method in self.standards.interface_methods:
            if hasattr(adapter_instance, method):
                try:
                    sig = inspect.signature(getattr(adapter_instance, method))
                    method_signatures[method] = str(sig)
                except Exception as e:
                    warnings.append(f"ç„¡æ³•æª¢æŸ¥æ–¹æ³• {method} çš„ç°½å: {e}")
        
        details["method_signatures"] = method_signatures
        details["missing_methods"] = missing_methods
        
        # è¨ˆç®—åˆ†æ•¸
        total_methods = len(self.standards.interface_methods)
        implemented_methods = total_methods - len(missing_methods)
        score = implemented_methods / total_methods if total_methods > 0 else 0
        
        execution_time = time.time() - start_time
        
        return StandardTestResult(
            test_name="Interface Standardization",
            adapter_name=adapter_name,
            passed=len(missing_methods) == 0,
            score=score,
            errors=errors,
            warnings=warnings,
            details=details,
            execution_time=execution_time
        )
    
    def test_response_format(self, adapter_name: str, adapter_instance: Any) -> StandardTestResult:
        """æ¸¬è©¦éŸ¿æ‡‰æ ¼å¼æ¨™æº–åŒ–"""
        start_time = time.time()
        errors = []
        warnings = []
        details = {}
        
        # æ¸¬è©¦processæ–¹æ³•çš„éŸ¿æ‡‰æ ¼å¼
        if hasattr(adapter_instance, 'process'):
            try:
                # ä½¿ç”¨ç°¡å–®çš„æ¸¬è©¦è¼¸å…¥
                test_input = {"test": "standardization"}
                response = adapter_instance.process(test_input)
                
                # æª¢æŸ¥éŸ¿æ‡‰æ ¼å¼
                format_issues = self._validate_response_format(response)
                if format_issues:
                    errors.extend(format_issues)
                
                details["sample_response"] = response
                details["response_type"] = type(response).__name__
                
            except Exception as e:
                errors.append(f"processæ–¹æ³•åŸ·è¡Œå¤±æ•—: {str(e)}")
        else:
            errors.append("ç¼ºå°‘processæ–¹æ³•")
        
        # æ¸¬è©¦get_capabilitiesæ–¹æ³•çš„éŸ¿æ‡‰æ ¼å¼
        if hasattr(adapter_instance, 'get_capabilities'):
            try:
                capabilities = adapter_instance.get_capabilities()
                capability_issues = self._validate_capability_format(capabilities)
                if capability_issues:
                    warnings.extend(capability_issues)
                
                details["capabilities"] = capabilities
                
            except Exception as e:
                warnings.append(f"get_capabilitiesæ–¹æ³•åŸ·è¡Œå¤±æ•—: {str(e)}")
        
        # è¨ˆç®—åˆ†æ•¸
        score = 1.0 if len(errors) == 0 else 0.5 if len(warnings) == 0 else 0.0
        
        execution_time = time.time() - start_time
        
        return StandardTestResult(
            test_name="Response Format",
            adapter_name=adapter_name,
            passed=len(errors) == 0,
            score=score,
            errors=errors,
            warnings=warnings,
            details=details,
            execution_time=execution_time
        )
    
    def test_error_handling(self, adapter_name: str, adapter_instance: Any) -> StandardTestResult:
        """æ¸¬è©¦éŒ¯èª¤è™•ç†æ¨™æº–åŒ–"""
        start_time = time.time()
        errors = []
        warnings = []
        details = {}
        
        error_test_cases = [
            {"input": None, "expected": "è™•ç†Noneè¼¸å…¥"},
            {"input": {}, "expected": "è™•ç†ç©ºå­—å…¸"},
            {"input": {"invalid": "data"}, "expected": "è™•ç†ç„¡æ•ˆæ•¸æ“š"},
            {"input": "invalid_string", "expected": "è™•ç†ç„¡æ•ˆå­—ç¬¦ä¸²"}
        ]
        
        error_handling_results = []
        
        if hasattr(adapter_instance, 'process'):
            for test_case in error_test_cases:
                try:
                    response = adapter_instance.process(test_case["input"])
                    
                    # æª¢æŸ¥æ˜¯å¦æ­£ç¢ºè™•ç†éŒ¯èª¤
                    if isinstance(response, dict):
                        if response.get("status") == "error":
                            error_handling_results.append({
                                "test": test_case["expected"],
                                "passed": True,
                                "response": response
                            })
                        else:
                            error_handling_results.append({
                                "test": test_case["expected"],
                                "passed": False,
                                "response": response,
                                "issue": "æœªè¿”å›éŒ¯èª¤ç‹€æ…‹"
                            })
                    else:
                        warnings.append(f"éŒ¯èª¤è™•ç†æ¸¬è©¦ '{test_case['expected']}' è¿”å›éå­—å…¸éŸ¿æ‡‰")
                        
                except Exception as e:
                    # æ‹‹å‡ºç•°å¸¸ä¹Ÿæ˜¯ä¸€ç¨®éŒ¯èª¤è™•ç†æ–¹å¼
                    error_handling_results.append({
                        "test": test_case["expected"],
                        "passed": True,
                        "exception": str(e)
                    })
        else:
            errors.append("ç¼ºå°‘processæ–¹æ³•ï¼Œç„¡æ³•æ¸¬è©¦éŒ¯èª¤è™•ç†")
        
        details["error_handling_results"] = error_handling_results
        
        # è¨ˆç®—åˆ†æ•¸
        if error_handling_results:
            passed_tests = sum(1 for result in error_handling_results if result["passed"])
            score = passed_tests / len(error_handling_results)
        else:
            score = 0.0
        
        execution_time = time.time() - start_time
        
        return StandardTestResult(
            test_name="Error Handling",
            adapter_name=adapter_name,
            passed=score >= 0.8,
            score=score,
            errors=errors,
            warnings=warnings,
            details=details,
            execution_time=execution_time
        )
    
    def test_capability_declaration(self, adapter_name: str, adapter_instance: Any) -> StandardTestResult:
        """æ¸¬è©¦èƒ½åŠ›è²æ˜æ¨™æº–åŒ–"""
        start_time = time.time()
        errors = []
        warnings = []
        details = {}
        
        if hasattr(adapter_instance, 'get_capabilities'):
            try:
                capabilities = adapter_instance.get_capabilities()
                
                # é©—è­‰èƒ½åŠ›è²æ˜æ ¼å¼
                format_issues = self._validate_capability_format(capabilities)
                if format_issues:
                    errors.extend(format_issues)
                
                # æª¢æŸ¥èƒ½åŠ›è²æ˜çš„å®Œæ•´æ€§
                if isinstance(capabilities, list):
                    details["capabilities_count"] = len(capabilities)
                    details["capabilities_list"] = capabilities
                elif isinstance(capabilities, dict):
                    details["capabilities_keys"] = list(capabilities.keys())
                    details["capabilities_dict"] = capabilities
                else:
                    errors.append(f"èƒ½åŠ›è²æ˜æ‡‰è©²æ˜¯listæˆ–dictï¼Œå¯¦éš›æ˜¯: {type(capabilities)}")
                
            except Exception as e:
                errors.append(f"get_capabilitiesæ–¹æ³•åŸ·è¡Œå¤±æ•—: {str(e)}")
        else:
            errors.append("ç¼ºå°‘get_capabilitiesæ–¹æ³•")
        
        # æª¢æŸ¥æ˜¯å¦æœ‰æ–‡æª”èªªæ˜èƒ½åŠ›
        if hasattr(adapter_instance, '__doc__') and adapter_instance.__doc__:
            details["has_documentation"] = True
            details["doc_length"] = len(adapter_instance.__doc__)
        else:
            warnings.append("ç¼ºå°‘é¡æ–‡æª”èªªæ˜")
        
        # è¨ˆç®—åˆ†æ•¸
        score = 1.0 if len(errors) == 0 else 0.5 if len(warnings) == 0 else 0.0
        
        execution_time = time.time() - start_time
        
        return StandardTestResult(
            test_name="Capability Declaration",
            adapter_name=adapter_name,
            passed=len(errors) == 0,
            score=score,
            errors=errors,
            warnings=warnings,
            details=details,
            execution_time=execution_time
        )
    
    def test_documentation_standards(self, adapter_name: str, adapter_info: Dict[str, Any]) -> StandardTestResult:
        """æ¸¬è©¦æ–‡æª”æ¨™æº–åŒ–"""
        start_time = time.time()
        errors = []
        warnings = []
        details = {}
        
        # æª¢æŸ¥é©é…å™¨æ–‡ä»¶çš„æ–‡æª”
        if "path" in adapter_info:
            adapter_path = Path(adapter_info["path"])
            
            # æª¢æŸ¥æ˜¯å¦æœ‰READMEæ–‡ä»¶
            readme_files = list(adapter_path.parent.glob("README*"))
            if readme_files:
                details["readme_files"] = [str(f) for f in readme_files]
            else:
                warnings.append("ç¼ºå°‘READMEæ–‡æª”")
            
            # æª¢æŸ¥ä»£ç¢¼æ–‡æª”
            try:
                with open(adapter_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    
                # æª¢æŸ¥æ¨¡å¡Šæ–‡æª”å­—ç¬¦ä¸²
                if '"""' in content or "'''" in content:
                    details["has_module_docstring"] = True
                else:
                    warnings.append("ç¼ºå°‘æ¨¡å¡Šæ–‡æª”å­—ç¬¦ä¸²")
                
                # æª¢æŸ¥é¡å’Œæ–¹æ³•æ–‡æª”
                docstring_count = content.count('"""') + content.count("'''")
                details["docstring_count"] = docstring_count
                
                if docstring_count < 2:
                    warnings.append("æ–‡æª”å­—ç¬¦ä¸²æ•¸é‡ä¸è¶³")
                    
            except Exception as e:
                errors.append(f"ç„¡æ³•è®€å–é©é…å™¨æ–‡ä»¶: {e}")
        
        # è¨ˆç®—åˆ†æ•¸
        score = 1.0 if len(errors) == 0 and len(warnings) <= 1 else 0.5 if len(errors) == 0 else 0.0
        
        execution_time = time.time() - start_time
        
        return StandardTestResult(
            test_name="Documentation Standards",
            adapter_name=adapter_name,
            passed=len(errors) == 0 and len(warnings) <= 1,
            score=score,
            errors=errors,
            warnings=warnings,
            details=details,
            execution_time=execution_time
        )
    
    def _validate_response_format(self, response: Any) -> List[str]:
        """é©—è­‰éŸ¿æ‡‰æ ¼å¼"""
        issues = []
        
        if not isinstance(response, dict):
            issues.append(f"éŸ¿æ‡‰æ‡‰è©²æ˜¯å­—å…¸ï¼Œå¯¦éš›æ˜¯: {type(response)}")
            return issues
        
        # æª¢æŸ¥å¿…éœ€å­—æ®µ
        required_fields = ["status"]
        for field in required_fields:
            if field not in response:
                issues.append(f"éŸ¿æ‡‰ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        
        # æª¢æŸ¥å­—æ®µé¡å‹
        if "status" in response and not isinstance(response["status"], str):
            issues.append(f"statuså­—æ®µæ‡‰è©²æ˜¯å­—ç¬¦ä¸²ï¼Œå¯¦éš›æ˜¯: {type(response['status'])}")
        
        if "data" in response:
            data_type = type(response["data"])
            valid_types = (dict, list, str, int, float, bool, type(None))
            if not isinstance(response["data"], valid_types):
                issues.append(f"dataå­—æ®µé¡å‹ç„¡æ•ˆ: {data_type}")
        
        return issues
    
    def _validate_capability_format(self, capabilities: Any) -> List[str]:
        """é©—è­‰èƒ½åŠ›è²æ˜æ ¼å¼"""
        issues = []
        
        if not isinstance(capabilities, (list, dict)):
            issues.append(f"èƒ½åŠ›è²æ˜æ‡‰è©²æ˜¯listæˆ–dictï¼Œå¯¦éš›æ˜¯: {type(capabilities)}")
            return issues
        
        if isinstance(capabilities, list):
            for i, cap in enumerate(capabilities):
                if not isinstance(cap, str):
                    issues.append(f"èƒ½åŠ›é … {i} æ‡‰è©²æ˜¯å­—ç¬¦ä¸²ï¼Œå¯¦éš›æ˜¯: {type(cap)}")
        
        elif isinstance(capabilities, dict):
            if "name" not in capabilities:
                issues.append("èƒ½åŠ›è²æ˜å­—å…¸ç¼ºå°‘nameå­—æ®µ")
        
        return issues
    
    def run_standardization_tests(self, adapter_name: str = None) -> List[StandardTestResult]:
        """é‹è¡Œæ¨™æº–åŒ–æ¸¬è©¦"""
        logger.info("é–‹å§‹MCPæ¨™æº–åŒ–æ¸¬è©¦...")
        
        # ç™¼ç¾é©é…å™¨
        adapters = self.discover_adapters()
        
        # é¸æ“‡è¦æ¸¬è©¦çš„é©é…å™¨
        if adapter_name:
            if adapter_name not in adapters:
                logger.error(f"æœªæ‰¾åˆ°é©é…å™¨: {adapter_name}")
                return []
            test_adapters = {adapter_name: adapters[adapter_name]}
        else:
            test_adapters = adapters
        
        results = []
        
        for name, adapter_info in test_adapters.items():
            logger.info(f"æ¸¬è©¦é©é…å™¨: {name}")
            
            # ç²å–é©é…å™¨å¯¦ä¾‹
            adapter_instance = adapter_info.get("instance")
            if not adapter_instance:
                logger.warning(f"ç„¡æ³•ç²å–é©é…å™¨å¯¦ä¾‹: {name}")
                continue
            
            # é‹è¡Œå„é …æ¨™æº–åŒ–æ¸¬è©¦
            test_methods = [
                self.test_interface_standardization,
                self.test_response_format,
                self.test_error_handling,
                self.test_capability_declaration
            ]
            
            adapter_results = []
            for test_method in test_methods:
                try:
                    result = test_method(name, adapter_instance)
                    adapter_results.append(result)
                    results.append(result)
                    
                    # æ›´æ–°çµ±è¨ˆ
                    category = result.test_name.lower().replace(" ", "_")
                    if category in self.stats["test_categories"]:
                        self.stats["test_categories"][category]["total"] += 1
                        if result.passed:
                            self.stats["test_categories"][category]["passed"] += 1
                            
                except Exception as e:
                    logger.error(f"æ¸¬è©¦ {test_method.__name__} å¤±æ•—: {e}")
            
            # æ–‡æª”æ¨™æº–åŒ–æ¸¬è©¦
            try:
                doc_result = self.test_documentation_standards(name, adapter_info)
                adapter_results.append(doc_result)
                results.append(doc_result)
                
                self.stats["test_categories"]["documentation"]["total"] += 1
                if doc_result.passed:
                    self.stats["test_categories"]["documentation"]["passed"] += 1
                    
            except Exception as e:
                logger.error(f"æ–‡æª”æ¨™æº–åŒ–æ¸¬è©¦å¤±æ•—: {e}")
            
            # è¨ˆç®—é©é…å™¨æ•´é«”é€šéç‹€æ…‹
            adapter_passed = all(r.passed for r in adapter_results)
            if adapter_passed:
                self.stats["passed_adapters"] += 1
            else:
                self.stats["failed_adapters"] += 1
            
            self.stats["tested_adapters"] += 1
        
        # è¨ˆç®—æ•´é«”åˆè¦æ€§
        if self.stats["tested_adapters"] > 0:
            self.stats["overall_compliance"] = self.stats["passed_adapters"] / self.stats["tested_adapters"]
        
        self.test_results = results
        logger.info(f"æ¨™æº–åŒ–æ¸¬è©¦å®Œæˆï¼Œæ¸¬è©¦äº† {self.stats['tested_adapters']} å€‹é©é…å™¨")
        
        return results
    
    def generate_standardization_report(self) -> str:
        """ç”Ÿæˆæ¨™æº–åŒ–æ¸¬è©¦å ±å‘Š"""
        report = f"""
# MCPæ¨™æº–åŒ–æ¸¬è©¦å ±å‘Š

## ğŸ“Š ç¸½é«”çµ±è¨ˆ
- **æ¸¬è©¦æ™‚é–“**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **ç¸½é©é…å™¨æ•¸**: {self.stats['total_adapters']}
- **å·²æ¸¬è©¦é©é…å™¨**: {self.stats['tested_adapters']}
- **é€šéé©é…å™¨**: {self.stats['passed_adapters']}
- **å¤±æ•—é©é…å™¨**: {self.stats['failed_adapters']}
- **æ•´é«”åˆè¦æ€§**: {self.stats['overall_compliance']:.1%}

## ğŸ“‹ æ¸¬è©¦é¡åˆ¥çµ±è¨ˆ
"""
        
        for category, stats in self.stats["test_categories"].items():
            if stats["total"] > 0:
                pass_rate = stats["passed"] / stats["total"]
                status = "âœ…" if pass_rate >= 0.9 else "âš ï¸" if pass_rate >= 0.7 else "âŒ"
                report += f"- {status} **{category.replace('_', ' ').title()}**: {stats['passed']}/{stats['total']} ({pass_rate:.1%})\n"
        
        report += f"""
## ğŸ” è©³ç´°æ¸¬è©¦çµæœ

### é©é…å™¨æ¸¬è©¦çµæœ
"""
        
        # æŒ‰é©é…å™¨åˆ†çµ„çµæœ
        adapter_results = {}
        for result in self.test_results:
            if result.adapter_name not in adapter_results:
                adapter_results[result.adapter_name] = []
            adapter_results[result.adapter_name].append(result)
        
        for adapter_name, results in adapter_results.items():
            overall_passed = all(r.passed for r in results)
            status = "âœ…" if overall_passed else "âŒ"
            avg_score = sum(r.score for r in results) / len(results) if results else 0
            
            report += f"""
#### {status} {adapter_name} (å¹³å‡åˆ†æ•¸: {avg_score:.1%})
"""
            
            for result in results:
                test_status = "âœ…" if result.passed else "âŒ"
                report += f"- {test_status} **{result.test_name}**: {result.score:.1%}"
                
                if result.errors:
                    report += f" - éŒ¯èª¤: {len(result.errors)}å€‹"
                if result.warnings:
                    report += f" - è­¦å‘Š: {len(result.warnings)}å€‹"
                
                report += f" ({result.execution_time:.3f}s)\n"
                
                # é¡¯ç¤ºä¸»è¦éŒ¯èª¤
                for error in result.errors[:2]:
                    report += f"  - âš ï¸ {error}\n"
        
        report += f"""
## ğŸ¯ æ”¹é€²å»ºè­°

### é«˜å„ªå…ˆç´š
"""
        
        # åˆ†æå¸¸è¦‹å•é¡Œ
        common_errors = {}
        for result in self.test_results:
            for error in result.errors:
                if error in common_errors:
                    common_errors[error] += 1
                else:
                    common_errors[error] = 1
        
        # é¡¯ç¤ºæœ€å¸¸è¦‹çš„éŒ¯èª¤
        sorted_errors = sorted(common_errors.items(), key=lambda x: x[1], reverse=True)
        for error, count in sorted_errors[:5]:
            report += f"- **{error}** (å½±éŸ¿ {count} å€‹æ¸¬è©¦)\n"
        
        report += f"""
### æ¨™æº–åŒ–æ”¹é€²
1. çµ±ä¸€æ¥å£æ–¹æ³•å¯¦ç¾
2. æ¨™æº–åŒ–éŸ¿æ‡‰æ ¼å¼
3. å®Œå–„éŒ¯èª¤è™•ç†æ©Ÿåˆ¶
4. è¦ç¯„èƒ½åŠ›è²æ˜æ ¼å¼
5. è£œå……æ–‡æª”èªªæ˜

## ğŸ“ˆ åˆè¦æ€§è©•ä¼°

{'âœ… ç³»çµ±é”åˆ°æ¨™æº–åŒ–è¦æ±‚' if self.stats['overall_compliance'] >= 0.9 else 'âš ï¸ ç³»çµ±éœ€è¦æ”¹é€²ä»¥é”åˆ°æ¨™æº–åŒ–è¦æ±‚' if self.stats['overall_compliance'] >= 0.7 else 'âŒ ç³»çµ±æœªé”åˆ°æ¨™æº–åŒ–è¦æ±‚'}

**æ•´é«”åˆè¦æ€§åˆ†æ•¸**: {self.stats['overall_compliance']:.1%}
"""
        
        return report

if __name__ == "__main__":
    framework = MCPStandardizedTestFramework()
    results = framework.run_standardization_tests()
    
    # ç”Ÿæˆå ±å‘Š
    report = framework.generate_standardization_report()
    
    # ä¿å­˜å ±å‘Š
    report_file = Path("mcp_standardization_test_report.md")
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… MCPæ¨™æº–åŒ–æ¸¬è©¦å®Œæˆ")
    print(f"ğŸ“„ å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    print(f"ğŸ¯ æ•´é«”åˆè¦æ€§: {framework.stats['overall_compliance']:.1%}")
    print(f"ğŸ“Š æ¸¬è©¦çµæœ: {framework.stats['passed_adapters']}/{framework.stats['tested_adapters']} å€‹é©é…å™¨é€šé")

